{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "eaee89c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c586c5",
   "metadata": {},
   "source": [
    "# Reading in and preprocessing scraped website text\n",
    "\n",
    "First, separate into sentences by splitting on full stops. Then covert each line to lowercase, remove numbers, punctuation and symbols, then whitespaces like tabs, etc. Finally tokenise each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "a16e7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matthew = False\n",
    "path = \"C:/Users/laure/OneDrive/Documenten/Project 3.1 APG Files/\"\n",
    "if matthew:\n",
    "    private_scrape = pd.read_excel('DATA/scrape_results/private_scrape_results_cleaned.xlsx')\n",
    "    public_scrape = pd.read_excel('DATA/scrape_results/public_scrape_results_cleaned.xlsx')\n",
    "else:\n",
    "    private_scrape = pd.read_excel(path + \"private_scrape_results_cleaned.xlsx\")\n",
    "    public_scrape = pd.read_excel(path + \"public_scrape_results_cleaned.xlsx\")\n",
    "\n",
    "dutch_stopwords = stopwords.words('dutch')\n",
    "dutch_months = ['Januari', \"Februari\", \"Maart\", \"April\", \"Mei\", \"Juni\", \"Juli\", \"Augustus\", \"September\", \"Oktober\", \"November\", \"December\", 'januari', \"februari\", \"maart\", \"april\", \"mei\", \"juni\", \"juli\", \"augustus\", \"september\", \"oktober\", \"november\", \"december\"]\n",
    "words_to_remove_dutch = dutch_stopwords + dutch_months\n",
    "dutch_pronouns = ['ik', 'je', 'jij', 'u', 'hij', 'ze', 'zij', 'hij', 'het', 'wij', 'we', 'jullie', 'me', 'mij', 'jou', 'hem', 'haar', 'ons', 'hen', 'hun', 'mijn', 'jouw', 'uw', 'zijn', 'ons', 'onze', 'zich', 'deze', 'die', 'dit', 'dat']\n",
    "dutch_stopwords = [word for word in words_to_remove_dutch if word not in dutch_pronouns]\n",
    "dutch_stopwords_and_pronouns = list(set(dutch_stopwords) | set(dutch_pronouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "outputs": [],
   "source": [
    "filter_stopwords = False\n",
    "filter_pronouns = True\n",
    "\n",
    "def preprocess_corpus(df):\n",
    "    paragraphs = []\n",
    "    sentences = []\n",
    "    for index, row in df.iterrows():\n",
    "        paragraphs.append(row.paragraph)\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        sentences.extend(re.split('[.|?|!|;|\\n|\\t]', para))\n",
    "\n",
    "    for index, sentence in enumerate(sentences):\n",
    "        sentence = sentence.replace('_x000D_', '')\n",
    "        sentence = sentence.replace('\\xa0', ' ')\n",
    "        sentence = sentence.replace('–', '')\n",
    "        sentence = sentence.replace('‘', '')\n",
    "        sentence = sentence.replace('’', '')\n",
    "        sentence = sentence.replace('”', '')\n",
    "        sentence = sentence.replace('“', '')\n",
    "        sentence = sentence.replace('á', 'a').replace('à', 'a').replace('ä', 'a').replace('â', 'a').replace('ã', 'a')\n",
    "        sentence = sentence.replace('ó', 'o').replace('ò', 'o').replace('ö', 'o').replace('ô', 'o').replace('õ', 'o')\n",
    "        sentence = sentence.replace('é', 'e').replace('è', 'e').replace('ë', 'e').replace('ê', 'e')\n",
    "        sentence = sentence.replace('í', 'i').replace('ì', 'i').replace('ï', 'i').replace('î', 'i')\n",
    "        sentence = sentence.replace('ú', 'u').replace('ù', 'u').replace('ü', 'u').replace('û', 'u')\n",
    "        sentence = sentence.replace('ý', 'y').replace('ÿ', 'y')\n",
    "        sentence = sentence.replace('ç', 'c')\n",
    "        sentence = sentence.replace('ñ', 'n')\n",
    "        sentence = sentence.lower()\n",
    "        sentence = re.sub(r'\\d+', '', sentence)\n",
    "        sentence = sentence.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "        if filter_stopwords and filter_pronouns:\n",
    "            words = sentence.split()\n",
    "            words = [word for word in words if word not in dutch_stopwords_and_pronouns]\n",
    "            new_sentence = \" \".join(words)\n",
    "        elif filter_stopwords:\n",
    "            words = sentence.split()\n",
    "            words = [word for word in words if word not in dutch_stopwords]\n",
    "            new_sentence = \" \".join(words)\n",
    "        elif filter_pronouns:\n",
    "            words = sentence.split()\n",
    "            words = [word for word in words if word not in dutch_pronouns]\n",
    "            new_sentence = \" \".join(words)\n",
    "        else:\n",
    "            new_sentence = sentence\n",
    "        if 'cms' in new_sentence:\n",
    "            new_sentence = ''\n",
    "        sentences[index] = new_sentence.strip()\n",
    "\n",
    "    sentences = list(filter(None, sentences))\n",
    "\n",
    "    return sentences\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "outputs": [],
   "source": [
    "# Preprocess the public and private scrape results\n",
    "processed_public_scrape = preprocess_corpus(public_scrape)\n",
    "length = len(processed_public_scrape)\n",
    "processed_private_scrape = preprocess_corpus(private_scrape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "outputs": [],
   "source": [
    "# Combine public and private scrape results\n",
    "processed_public_scrape.extend(processed_private_scrape)\n",
    "processed_scrapes = processed_public_scrape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "outputs": [],
   "source": [
    "# Convert to dataframe\n",
    "processed_df = pd.DataFrame(processed_scrapes, columns=['sentences'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "filename = 'public_and_private_sentences_{}_filtered.csv'.format('all' if filter_stopwords and filter_pronouns else 'stopwords' if filter_stopwords else 'pronouns' if filter_pronouns else 'none')\n",
    "if matthew:\n",
    "    processed_df.to_csv('DATA/scrape_results/' + filename, index=False)\n",
    "\n",
    "else:\n",
    "    processed_df.to_csv(path + filename, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}