{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaee89c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c586c5",
   "metadata": {},
   "source": [
    "# Reading in and preprocessing scraped website text\n",
    "\n",
    "First, seperate into sentences by splitting on full stops. Then covert each line to lowercase, remove numbers, punctuation and symbols, then whitespaces like tabs, etc. Finally tokenise each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a16e7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "private_scrape = pd.read_excel('DATA/scrape_results/private_scrape_results_cleaned.xlsx')\n",
    "public_scrape = pd.read_excel('DATA/scrape_results/public_scrape_results_cleaned.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "af5c0a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(df):\n",
    "    paragraphs = []\n",
    "    sentences = []\n",
    "    for index, row in df.iterrows():\n",
    "        paragraphs.append(row.paragraph)\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        sentences.extend(re.split('[.|?|!|;|\\n|\\t]', para))\n",
    "        \n",
    "    for index, sentence in enumerate(sentences):\n",
    "        sentence = sentence.replace('_x000D_', '')\n",
    "        sentence = sentence.replace('\\xa0', '')\n",
    "        sentence = sentence.replace('–', '')\n",
    "        sentence = sentence.replace('‘', '')\n",
    "        sentence = sentence.replace('’', '')\n",
    "        sentence = sentence.replace('“', '')\n",
    "        sentence = sentence.replace('”', '')\n",
    "        sentence = sentence.lower()\n",
    "        sentence = re.sub(r'\\d+', '', sentence)\n",
    "        sentence = sentence.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "        sentences[index] = sentence.strip()\n",
    "        \n",
    "    sentences = list(filter(None, sentences))\n",
    "        \n",
    "    return sentences\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cc281544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the public and private scrape results\n",
    "processed_public_scrape = preprocess_corpus(public_scrape)\n",
    "length = len(processed_public_scrape)\n",
    "processed_private_scrape = preprocess_corpus(private_scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "14f6562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine public and private scrape results\n",
    "processed_public_scrape.extend(processed_private_scrape)\n",
    "processed_scrapes = processed_public_scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d978dac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe\n",
    "processed_df = pd.DataFrame(processed_scrapes, columns=['sentences'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "95c48ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "processed_df.to_csv('DATA/scrape_results/public_and_private_sentences.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
