{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Change this variable and the path in the else statement below.\n",
    "laurence = True\n",
    "path = None\n",
    "if laurence:\n",
    "    path = \"C:/Users/laure/OneDrive/Documenten/Project 3.1 APG Files/\"\n",
    "else:\n",
    "    path = \"C:/Users/01din/OneDrive/Documenten/apg-data/\"\n",
    "\n",
    "private_scrape = pd.read_excel(path + \"private_scrape_results.xlsx\")\n",
    "public_scrape = pd.read_excel(path + \"public_scrape_results.xlsx\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Storing all of the records of 'public_scrape' in English in a separate dataframe. 'private_scrape' does not contain any records in\n",
    "# English so this is not needed there.\n",
    "public_scrape_english = public_scrape.loc[public_scrape['full_url'].str.contains(\"english\", case=False)]\n",
    "\n",
    "# Storing all of the records of 'public_scrape' in Dutch in a separate dataframe.\n",
    "public_scrape_dutch = public_scrape.loc[~public_scrape['full_url'].str.contains(\"english\", case=False)]\n",
    "\n",
    "# Obtaining the paragraphs of these scrape results and converting them to lists, making them easier to iterare over.\n",
    "private_corpus = private_scrape.paragraph.tolist()\n",
    "public_corpus = public_scrape_dutch.paragraph.tolist()\n",
    "public_corpus_english = public_scrape_english.paragraph.tolist()\n",
    "\n",
    "# Adding the 'private_corpus' and 'public_corpus' as they are both in Dutch.\n",
    "corpus_dutch = public_corpus + private_corpus\n",
    "corpus_english = public_corpus_english\n",
    "\n",
    "# Defining which words in Dutch we want to remove before starting computing the tf-idf matrix.\n",
    "dutch_stopwords = stopwords.words('dutch')\n",
    "dutch_months = ['Januari', \"Februari\", \"Maart\", \"April\", \"Mei\", \"Juni\", \"Juli\", \"Augustus\", \"September\", \"Oktober\", \"November\", \"December\", 'januari', \"februari\", \"maart\", \"april\", \"mei\", \"juni\", \"juli\", \"augustus\", \"september\", \"oktober\", \"november\", \"december\"]\n",
    "words_to_remove_dutch = dutch_stopwords + dutch_months\n",
    "\n",
    "# Defining which words in English we want to remove before starting computing the tf-idf matrix.\n",
    "english_stopwords = stopwords.words('english')\n",
    "english_months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\", \"january\", \"february\", \"march\", \"april\", \"may\", \"june\", \"july\", \"august\", \"september\", \"october\", \"november\", \"december\"]\n",
    "words_to_remove_english = english_stopwords + english_months"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def preprocess_corpus(corpus, words_to_remove, dutch):\n",
    "    all_words = []\n",
    "    sentences = []\n",
    "\n",
    "    for doc in corpus:\n",
    "        sentences.extend(re.split('[.|?|!|;|\\n|\\t]', str(doc)))\n",
    "\n",
    "    for index, sentence in enumerate(corpus):\n",
    "        sentence = str(sentence).lower()\n",
    "        sentence = sentence.replace(\"á\", \"a\").replace(\"é\", \"e\").replace(\"è\", \"e\").replace(\"ó\", \"o\").replace(\"ò\", \"o\").replace(\"í\", \"i\")\n",
    "        sentence = sentence.translate(str.maketrans(\"\", \"\", (string.punctuation + \"’\")))\n",
    "        sentence = \"\".join([i for i in sentence if not i.isdigit()])\n",
    "        while \"  \" in sentence:\n",
    "            sentence = sentence.replace(\"  \", \" \")\n",
    "        all_words += (sentence.split())\n",
    "    all_words = list(set(all_words))\n",
    "\n",
    "    \n",
    "    for index, sentence in enumerate(corpus):\n",
    "        sentence = str(sentence).lower()\n",
    "        sentence = sentence.replace(\"á\", \"a\").replace(\"é\", \"e\").replace(\"è\", \"e\").replace(\"ó\", \"o\").replace(\"ò\", \"o\").replace(\"í\", \"i\")\n",
    "        sentence = sentence.translate(str.maketrans(\"\", \"\", (string.punctuation + \"’\")))\n",
    "        sentence = \"\".join([i for i in sentence if not i.isdigit()])\n",
    "        while \"  \" in sentence:\n",
    "            sentence = sentence.replace(\"  \", \" \")\n",
    "        \n",
    "        words = sentence.split()\n",
    "        stemmed_sentence = []\n",
    "        \n",
    "        for word in words:\n",
    "            if \"xd\" in word and word != 'exdeelnemers':\n",
    "                word = word.replace(\"xd\", \"\")\n",
    "            if word not in words_to_remove:\n",
    "                if dutch:\n",
    "                    if word.endswith(\"ing\") and word[:-3] in all_words:\n",
    "                        stemmed_sentence.append(word[:-3])\n",
    "                    elif word.endswith(\"s\") and word[:-1] in all_words:\n",
    "                        stemmed_sentence.append(word[:-1])\n",
    "                    elif word.endswith(\"ig\") and word[:-2] in all_words:\n",
    "                        stemmed_sentence.append(word[:-2])\n",
    "                    elif word.endswith(\"isme\") and word[:-4] in all_words:\n",
    "                        stemmed_sentence.append(word[:-4])\n",
    "                    elif word.endswith(\"lijk\") and word[:-4] in all_words:\n",
    "                        stemmed_sentence.append(word[:-4])\n",
    "                    elif word.endswith(\"e\") and word[:-1] in all_words:\n",
    "                        stemmed_sentence.append(word[:-1])\n",
    "                    elif word.endswith(\"en\") and word[:-2] in all_words:\n",
    "                        stemmed_sentence.append(word[:-2])\n",
    "                    else:\n",
    "                        stemmed_sentence.append(word)\n",
    "                elif not dutch:\n",
    "                    if word.endswith(\"s\") and word[:-1] in all_words:\n",
    "                        stemmed_sentence.append(word[:-1])\n",
    "                    elif word.endswith(\"ism\") and word[:-3] in all_words:\n",
    "                        stemmed_sentence.append(word[:-3])\n",
    "                    elif word.endswith(\"ed\") and word[:-2] in all_words:\n",
    "                        stemmed_sentence.append(word[:-2])\n",
    "                    elif word.endswith(\"al\") and word[:-2] in all_words:\n",
    "                        stemmed_sentence.append(word[:-2])\n",
    "                    elif word.endswith(\"ist\") and word[:-3] in all_words:\n",
    "                        stemmed_sentence.append(word[:-3])\n",
    "                    elif word.endswith(\"ity\") and word[:-3] in all_words:\n",
    "                        stemmed_sentence.append(word[:-3])\n",
    "                    elif word.endswith(\"ness\") and word[:-4] in all_words:\n",
    "                        stemmed_sentence.append(word[:-4])\n",
    "                    else:\n",
    "                        stemmed_sentence.append(word)\n",
    "\n",
    "        stemmed_sentence = \" \".join(stemmed_sentence)\n",
    "        sentences[index] = stemmed_sentence\n",
    "    return sentences, all_words\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [33]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m dutch_sentences, all_words_dutch \u001B[38;5;241m=\u001B[39m \u001B[43mpreprocess_corpus\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcorpus_dutch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwords_to_remove_dutch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m english_sentences, all_words_english \u001B[38;5;241m=\u001B[39m preprocess_corpus(corpus_english, words_to_remove_english, \u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Input \u001B[1;32mIn [32]\u001B[0m, in \u001B[0;36mpreprocess_corpus\u001B[1;34m(corpus, words_to_remove, dutch)\u001B[0m\n\u001B[0;32m     67\u001B[0m                     stemmed_sentence\u001B[38;5;241m.\u001B[39mappend(word)\n\u001B[0;32m     69\u001B[0m     stemmed_sentence \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(stemmed_sentence)\n\u001B[1;32m---> 70\u001B[0m     sentences[index] \u001B[38;5;241m=\u001B[39m stemmed_sentence\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sentences, all_words\n",
      "\u001B[1;31mIndexError\u001B[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "dutch_sentences, all_words_dutch = preprocess_corpus(corpus_dutch, words_to_remove_dutch, True)\n",
    "english_sentences, all_words_english = preprocess_corpus(corpus_english, words_to_remove_english, False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "dff = pd.DataFrame(all_words_dutch, columns=['all_words'])\n",
    "dff.to_csv(path + 'all_words_dutch.csv', index=False)\n",
    "\n",
    "dfe = pd.DataFrame(all_words_english, columns=['all_words'])\n",
    "dfe.to_csv(path + 'all_words_english.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "dutch_sentences.extend(english_sentences)\n",
    "all_sentences = dutch_sentences"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Convert to dataframe\n",
    "processed_df = pd.DataFrame(all_sentences, columns=['sentences'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "filename = 'public_and_private_sentences_filtered.csv'\n",
    "if laurence:\n",
    "    processed_df.to_csv(path + filename, index=False)\n",
    "else:\n",
    "    processed_df.to_csv('DATA/scrape_results/' + filename, index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "keywords_tf_idf = pd.read_csv(path + \"tf_idf_keywords_try.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "keywords_tf_idf = keywords_tf_idf[\"0\"].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aan\n",
      "aanbevelingen\n",
      "aansluiten\n",
      "aarde\n",
      "abpcommunicatieplannernl\n",
      "abpnl\n",
      "abpnlanwcompensatie\n",
      "abpnlarbeidsongeschiktheid\n",
      "abpnldereisvanjeleven\n",
      "abpnldigid\n",
      "abpnlkeuzehulp\n",
      "abpnlmail\n",
      "abpnlmeerwaarde\n",
      "abpnlnabestaanden\n",
      "abpnlpensioen\n",
      "abpnlpensioninformation\n",
      "abpnlverkiezingen\n",
      "abpnlverlagen\n",
      "abpomdat\n",
      "abppensioenspelnl\n",
      "activeertlees\n",
      "adajavloetabpeu\n",
      "ai\n",
      "al\n",
      "als\n",
      "altijd\n",
      "andere\n",
      "anderen\n",
      "anders\n",
      "appvia\n",
      "armen\n",
      "ashakhoenkhoenabpeu\n",
      "aub\n",
      "bedragen\n",
      "bedreigingen\n",
      "begrijpen\n",
      "behaalde\n",
      "belangrijkekeuzesnl\n",
      "belastingdienstnl\n",
      "beleggingen\n",
      "beleggingstips\n",
      "bemoei\n",
      "bereiken\n",
      "bertram\n",
      "beste\n",
      "bevoegde\n",
      "bloedingen\n",
      "boeken\n",
      "bolcom\n",
      "bordjes\n",
      "bouwen\n",
      "brdugmabpnl\n",
      "brengen\n",
      "bufferverplichting\n",
      "businessasusual\n",
      "catastrophe\n",
      "challengebased\n",
      "clubs\n",
      "clueless\n",
      "collegas\n",
      "daar\n",
      "dan\n",
      "dat\n",
      "dbetonprinten\n",
      "deelnemers\n",
      "demping\n",
      "den\n",
      "denken\n",
      "diensten\n",
      "digidnl\n",
      "digidvraag\n",
      "digitale\n",
      "dingen\n",
      "diplomas\n",
      "discretionaire\n",
      "dit\n",
      "diverse\n",
      "dobzabpnl\n",
      "docenten\n",
      "doen\n",
      "dominiquedijkhuisabpeu\n",
      "donkergroene\n",
      "doodgaan\n",
      "door\n",
      "dus\n",
      "economische\n",
      "ed\n",
      "een\n",
      "eerlijke\n",
      "eigenlijk\n",
      "eindelijk\n",
      "enienl\n",
      "erkende\n",
      "ervaringen\n",
      "esgroadmap\n",
      "ethische\n",
      "fdnl\n",
      "feiten\n",
      "feministen\n",
      "finalisten\n",
      "financiers\n",
      "fitboost\n",
      "fitoal\n",
      "flexibele\n",
      "flitswebinars\n",
      "formuleer\n",
      "fouten\n",
      "frontofficeincapgnl\n",
      "functionarisgegevensbeschermingapgnl\n",
      "gaten\n",
      "gebrekkige\n",
      "gebruiken\n",
      "geen\n",
      "gekust\n",
      "geldfitnl\n",
      "gemeentelijke\n",
      "generatiepact\n",
      "genieten\n",
      "gepensioneerde\n",
      "geprinte\n",
      "gerechtvaardigde\n",
      "gereviseerde\n",
      "gezonde\n",
      "gezondverzekerdnl\n",
      "groepjes\n",
      "gronden\n",
      "had\n",
      "heb\n",
      "hebben\n",
      "hebzucht\n",
      "heeft\n",
      "heen\n",
      "helpdesketilnl\n",
      "helpen\n",
      "herziening\n",
      "hetcaknlregelingen\n",
      "hier\n",
      "hij\n",
      "hoe\n",
      "holladijee\n",
      "honderden\n",
      "hoofdmoot\n",
      "houden\n",
      "httpswwwrealitychecknl\n",
      "httpwwwwijzeringeldzakennlpensioen\n",
      "hufterproof\n",
      "huisfotograaf\n",
      "huishoudboekjeapp\n",
      "huishoudens\n",
      "hulpmiddelen\n",
      "iedereen\n",
      "ik\n",
      "immens\n",
      "in\n",
      "infodigidnl\n",
      "ingesprekmetabpnl\n",
      "ingroeimodel\n",
      "inhaalto\n",
      "inhaaltoelage\n",
      "interesses\n",
      "internationale\n",
      "intreebericht\n",
      "investeerders\n",
      "investeringen\n",
      "irrelevante\n",
      "is\n",
      "jaardit\n",
      "jaarverslagabpnl\n",
      "jawel\n",
      "jongere\n",
      "jongeren\n",
      "kanjer\n",
      "kansen\n",
      "kantenklaar\n",
      "kijken\n",
      "kinderen\n",
      "klaarblijkelijk\n",
      "kleine\n",
      "klimaatrisicos\n",
      "knap\n",
      "koepels\n",
      "komen\n",
      "kopen\n",
      "krijgen\n",
      "kunnen\n",
      "lasten\n",
      "laten\n",
      "leefjepensioennl\n",
      "leerlingen\n",
      "lees\n",
      "leiden\n",
      "leraarnl\n",
      "letsel\n",
      "levensbestendig\n",
      "leveren\n",
      "lijfrentepremies\n",
      "lineair\n",
      "maakte\n",
      "maar\n",
      "maatjes\n",
      "maatschappelijke\n",
      "mailadres\n",
      "mantelzorgcompliment\n",
      "maryjeoslabbekoornabpeu\n",
      "medewerkers\n",
      "meer\n",
      "meewerkte\n",
      "menselijke\n",
      "mensen\n",
      "mensenmens\n",
      "mij\n",
      "mijnabpnl\n",
      "mijnabpnluwberichten\n",
      "mijngeldzakennl\n",
      "mijnleraarverteldenl\n",
      "mijnpensioenoverzichtnl\n",
      "mijnwaardeoverdrachtnl\n",
      "mining\n",
      "moesten\n",
      "moeten\n",
      "moneyfitnl\n",
      "museumdag\n",
      "na\n",
      "naar\n",
      "nan\n",
      "nbeschikking\n",
      "neimednl\n",
      "nemesis\n",
      "nettopensioenabpnl\n",
      "niet\n",
      "nietgroene\n",
      "nieuwe\n",
      "nog\n",
      "noreplyonderzoekabpnl\n",
      "nu\n",
      "nulmeting\n",
      "oa\n",
      "obligaties\n",
      "oderndermindefnl\n",
      "of\n",
      "oh\n",
      "omdat\n",
      "ome\n",
      "onder\n",
      "onderzoekabpblauwsurveycom\n",
      "onderzoekabpnl\n",
      "onderzoekviametfeedbacknl\n",
      "ondubbelzinnig\n",
      "onnodige\n",
      "ons\n",
      "ontvangen\n",
      "ontwikkelen\n",
      "ook\n",
      "oooh\n",
      "opbouwend\n",
      "opknipt\n",
      "opmerkingen\n",
      "optiepakket\n",
      "oude\n",
      "oudere\n",
      "ouders\n",
      "ouderwetse\n",
      "overboeken\n",
      "overbruggingsbaan\n",
      "overeenkomsten\n",
      "overige\n",
      "overlevers\n",
      "parkeer\n",
      "partners\n",
      "patiënten\n",
      "pensioenook\n",
      "pensioenopbouwaanvullenabpnl\n",
      "pensioenpluimnl\n",
      "pensioenpotjes\n",
      "pensioenvannederlandnl\n",
      "pensionados\n",
      "perfecte\n",
      "pfzwnlsamenloop\n",
      "plug\n",
      "premieincassoabpnl\n",
      "premievrije\n",
      "producten\n",
      "profielen\n",
      "progressieve\n",
      "propvorming\n",
      "realistic\n",
      "realitychecknl\n",
      "rebels\n",
      "referentieperiode\n",
      "regels\n",
      "relatiebeheerabpnl\n",
      "relove\n",
      "remontabele\n",
      "richting\n",
      "ring\n",
      "risicovrije\n",
      "saaie\n",
      "saudade\n",
      "schooljuffrouw\n",
      "schoonmaakactie\n",
      "schrijvervanonzineu\n",
      "schuldbewijs\n",
      "schulden\n",
      "sectormanagementabpnl\n",
      "skid\n",
      "slangen\n",
      "slapers\n",
      "smart\n",
      "soms\n",
      "spelen\n",
      "sporten\n",
      "spotlights\n",
      "srchttpswwwabpnlwerkgevershandigetoolshrchecklistchecklistwegwijsinuwpensioenaspxiframe\n",
      "srchttpswwwabpnlwerkgevershandigetoolsintranetservicestartpaginaaspxiframe\n",
      "srchttpswwwyoutubecomembedyiviifcdm\n",
      "staatsleningen\n",
      "stadszakennl\n",
      "statafelgesprekken\n",
      "steunpakket\n",
      "stout\n",
      "studenten\n",
      "studies\n",
      "sturende\n",
      "svbnl\n",
      "svbnlaow\n",
      "teamcaptains\n",
      "techleapnl\n",
      "tegen\n",
      "teksten\n",
      "temporisering\n",
      "therapeuten\n",
      "thomasvandijkabpeu\n",
      "tijdens\n",
      "tnv\n",
      "toch\n",
      "toegekendwe\n",
      "toekomsten\n",
      "toen\n",
      "tonen\n",
      "tot\n",
      "trams\n",
      "trouwens\n",
      "tussenpensioen\n",
      "tweakt\n",
      "tweedehandswinkels\n",
      "typenkan\n",
      "uitingen\n",
      "uitkijken\n",
      "uitknop\n",
      "uitsluiten\n",
      "uitsluiting\n",
      "uitstekende\n",
      "uw\n",
      "uwmeningonderzoekabpnl\n",
      "vale\n",
      "van\n",
      "vd\n",
      "veel\n",
      "vele\n",
      "verantwoorden\n",
      "verbruiken\n",
      "vergaderingen\n",
      "vergoedingen\n",
      "verkoopklaar\n",
      "verlatijns\n",
      "verplichte\n",
      "verveelde\n",
      "vinden\n",
      "virale\n",
      "vissen\n",
      "vlnr\n",
      "volwassenen\n",
      "voor\n",
      "voorkomen\n",
      "voorwaardenmeer\n",
      "vrijwilligers\n",
      "vrouwenemancipatie\n",
      "vs\n",
      "waarde\n",
      "walking\n",
      "wandelen\n",
      "waren\n",
      "was\n",
      "wat\n",
      "we\n",
      "weduwen\n",
      "weglekken\n",
      "welke\n",
      "werken\n",
      "werkgeversadministratieabpnl\n",
      "werkte\n",
      "wijzigen\n",
      "wil\n",
      "wonen\n",
      "worden\n",
      "wordt\n",
      "worstelen\n",
      "wwwabpnl\n",
      "wwwabpnlaanvulling\n",
      "wwwabpnlreisvanjeleven\n",
      "wwwmijnpensioenoverzichtnl\n",
      "wwwmijnwaardeoverdrachtnl\n",
      "wwwombudsmanpensioenennl\n",
      "wwwpensioenvannederlandnl\n",
      "wwwportereneenl\n",
      "wwwrealitychecknl\n",
      "wwwrijksoverheidnl\n",
      "wwwwensambulancebrabantnl\n",
      "zelfliefde\n",
      "zelfs\n",
      "zich\n",
      "zij\n",
      "zijn\n",
      "zm\n",
      "zo\n",
      "zoals\n",
      "zorgsaamwonennl\n",
      "zorgsparen\n",
      "zorgteamzcabpnl\n",
      "zou\n",
      "zwarte\n",
      "421\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "list_words = []\n",
    "for sentence in all_sentences:\n",
    "    words = sentence.split()\n",
    "    for word in words:\n",
    "        list_words.append(word)\n",
    "\n",
    "for keyword in keywords_tf_idf:\n",
    "    if keyword not in list_words:\n",
    "        counter += 1\n",
    "        print(keyword)\n",
    "\n",
    "\n",
    "\n",
    "print(counter)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "όόk\n"
     ]
    }
   ],
   "source": [
    "print(keywords_tf_idf[17074])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "keywords_tf_idf_new = pd.read_csv(path + \"tf_idf_keywords_try.csv\")\n",
    "keywords_tf_idf_new = keywords_tf_idf_new[\"0\"].tolist()\n",
    "\n",
    "keywords_tf_idf = pd.read_csv(path + \"tf_idf_keywords.csv\")\n",
    "keywords_tf_idf = keywords_tf_idf[\"0\"].tolist()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "difference = [x for x in keywords_tf_idf_new if x not in keywords_tf_idf]\n",
    "print(difference)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}