{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF class. Contains methods which can easily access relevant information from the csv file which the class reads, which represents the TF-IDF model.\n",
    "\n",
    "TF-IDF stands for Term Frequency - Inverse Document Frequency. It gives each keyword-document combination a weight, based on how often it occurs in the document, but also based on how often it occurs in all documents. This ensures that words which occur often in many documents do not receive high weights, rather only words which are relatively unique to a document and occur frequently in that document get high weights.\n",
    "\n",
    "If all documents are about topic A, we do not care that document x contains is about document A.\n",
    "\n",
    "Implementation wise, the TF-IDF is a csv file with each row representing a document and each column representing a keyword, the value at i,j represents the weight that keyword j has in document i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdf:\n",
    "    def __init__(self):\n",
    "        # Loading in the tf-idf\n",
    "        # Rows are documents, the first column is the document id\n",
    "        # Columns are keywords, the first row is the keyword id\n",
    "        self.tfidf = pd.read_csv(\"../data/tf_idf/tf_idf_time_weighted.csv\")\n",
    "\n",
    "        # Loading in the keywords\n",
    "        # Two columns, column 1 is id, column 2 is keyword\n",
    "        # We can access the weight in the tf-idf by first accessing the id number from the keyword file\n",
    "        self.tfidf_keywords = pd.read_csv(\"../data/tf_idf/tf_idf_keywords_new.csv\")\n",
    "        self.tfidf_keywords.columns = [\"id\", \"keyword\"]\n",
    "\n",
    "    def get_id_by_keyword(self, keyword):\n",
    "        return self.tfidf_keywords.id.iloc[self.tfidf_keywords[self.tfidf_keywords.keyword == keyword].index].values[0]\n",
    "\n",
    "\n",
    "    def get_keyword_by_id(self, id):\n",
    "        return self.tfidf_keywords.loc[self.tfidf_keywords.id==id, 'keyword'].iloc[0]\n",
    "    # Method to get the tfidf value of a keyword in a page\n",
    "    def get_tf_idf_value(self, page_id, keyword):\n",
    "        keyword_id = self.get_id_by_keyword(keyword)\n",
    "        return self.tfidf.iloc[page_id-1, keyword_id + 1]\n",
    "\n",
    "    def get_all_keywords_by_id(self, page_id):\n",
    "        keywords = self.tfidf.iloc[page_id-1][1:].values\n",
    "        return keywords\n",
    "\n",
    "    def get_all_keywords_by_id_normalized(self, page_id):\n",
    "        keywords_weights = self.get_all_keywords_by_id(page_id)\n",
    "        sum_value = sum(keywords_weights)\n",
    "        if sum_value == 0:\n",
    "            return keywords_weights\n",
    "        keywords_weights_normalized = keywords_weights/sum_value\n",
    "        return keywords_weights_normalized\n",
    "\n",
    "    def get_number_of_keywords(self):\n",
    "        return self.tfidf_keywords.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfIdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the dataset of visits, used to test the information need prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic = lambda x: literal_eval(x)\n",
    "\n",
    "conv = {'url_id_path': generic,\n",
    "        'seconds_spent_path': generic}\n",
    "df = pd.read_csv('data/clickdata/dataNoUnscrapedVisitsOrUnder20Sec.csv', converters=conv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create seperate dataframes for the paths taken and for the seconds spent on each url.\n",
    "In paths, index 0 gives a list of urls, the equivalent index 0 in seconds represents how many seconds the user spent on the equal index urls.\n",
    "\n",
    "ATTENTION!!!!!!!!!!!!!!!!!!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3583310\n"
     ]
    }
   ],
   "source": [
    "paths = df.url_id_path\n",
    "secs = df.seconds_spent_path\n",
    "\n",
    "\n",
    "print(len(paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3534\n",
      "8038\n",
      "8983\n"
     ]
    }
   ],
   "source": [
    "list = tfidf.get_all_keywords_by_id(1)\n",
    "for i in range(0, len(list)):\n",
    "    if list[i]!=0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ")Simplified implementation of IUNIS, which simply looks at the keywords which the user comes across, does not use the adjacency matrix, proximal cues, and spreading activation.\n",
    "It seems that these are mostly important for WUFIS, which we are not interested in, thus implementing it is not worth the effort.\n",
    "\n",
    "Input is the ordered list of page id's that the user has visited.\n",
    "For each page, take the TF-IDF values from that page, which is a row of keywords, with either 0 if the keyword is not present or [0,1] if it is.\n",
    "\n",
    "Then, for each next page, we add the TF-IDF values onto the existing weights.\n",
    "\n",
    "Eventually we can sort the list and we will have the keywords with the highest weight on top, which then represents the most relevant keywords in the visit up until now, and acts as our prediction for what the user is looking for.\n",
    "Instead of only looking at the user alone, we can also compare their information need to information needs of other users, and by looking at where the other users end up, we can predict where our user might want to end up.\n",
    "\n",
    "Optionally, a decay factor can be introdced. Essentially, every iteration, all values are divided by a factor, meaning that keywords on recent pages are more biased and weighted more heavily.\n",
    "\n",
    "It is also possible to give more weight to pages based on how much time the user spent on that page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "#Method which essentially just takes the keywords and their weights on each page the user visits, continues to the next url, and then sums the weights.\n",
    "#Be sure to realise that only passing a path will execute the normal implementation, which simply sums all new tf-idf values of each url.\n",
    "#This is because the default decay_factor value is 1, meaning that nothing changes, and the default secs is None, if that is None, the if statement with secs is never entered and we do not take time into account.\n",
    "#Sorted gives an option to sort the vector before returning, this puts the most relevant keywords on top, but does not allow for easy similarity comparison, thus should only be used if this is not the intention\n",
    "def find_keyword_weights(path, decay_factor=1, secs=None, sorted=False):\n",
    "    #initiate array of weights (weights start as 0, size=num of keywords)\n",
    "    weights = np.zeros(tfidf.get_number_of_keywords())\n",
    "    #ensures all output is visible\n",
    "    pd.options.display.max_rows = 0\n",
    "    #Iterate over each page url\n",
    "    for i in range(len(path)):\n",
    "        #Divide the weights by the decay factor (1 by default, no decay in that case)\n",
    "        weights = weights/decay_factor\n",
    "        #Initialize the tf-idf weights of the current page\n",
    "        new_weights = tfidf.get_all_keywords_by_id_normalized(path[i])\n",
    "        #If we are taking time into account, multiply the weights by the amount of time spent on this page\n",
    "        if secs is not None:\n",
    "            new_weights*=secs[i]\n",
    "        #Add the new weights to the existing weights\n",
    "        weights += new_weights\n",
    "        #Normalize such that the largest value becomes 1\n",
    "        if max(weights)==0:\n",
    "            return weights\n",
    "        weights /= max(weights)\n",
    "    #Option to sort s.t. max weights are on top.\n",
    "    if sorted:\n",
    "        df = DataFrame(weights, columns=['weights'])\n",
    "        return df.sort_values(by=['weights'], ascending=False)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method which calculates keywords of a visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(keys, values):\n",
    "    result = {} # empty dictionary\n",
    "    for key, value in zip(keys, values):\n",
    "        if value != 0 and not np.isnan(value) and key != 'laxxxxxxxxx' and key!= 'boxxxx':\n",
    "            result[key] = value\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def remove_keywordless_pages(path, seconds):\n",
    "    indices_to_remove = []\n",
    "    for i in range(len(path)):\n",
    "        if path[i]>1494:\n",
    "            indices_to_remove.append(i)\n",
    "    for i in range(len(indices_to_remove)-1, -1, -1):\n",
    "        index = indices_to_remove[i]\n",
    "        path.pop(index)\n",
    "        seconds.pop(index)\n",
    "    return path, seconds"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_keywords_of_complete_visit(min_visit_size, paths):\n",
    "    dicts = []\n",
    "    keys = []\n",
    "    for i in range(0, tfidf.get_number_of_keywords()):\n",
    "        keys.append(tfidf.get_keyword_by_id(i))\n",
    "\n",
    "    for i in range(len(paths)):\n",
    "        path = paths[i]\n",
    "        if i % 10000 == 0:\n",
    "            print(i, 'out of', len(paths))\n",
    "        path[:] = [x for x in path if x<=1555]\n",
    "        if len(path)>=min_visit_size:\n",
    "            weights = find_keyword_weights(path, decay_factor=7)\n",
    "            keywords_weights = create_dictionary(keys, weights)\n",
    "            id_need = (i, keywords_weights)\n",
    "            dicts.append(id_need)\n",
    "            \n",
    "    return dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 3583310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yv/gpc5sh7j5k3cls_fv_dpzntc0000gn/T/ipykernel_836/3435437501.py:32: RuntimeWarning: invalid value encountered in true_divide\n",
      "  keywords_weights_normalized = keywords_weights/sum_value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 out of 3583310\n",
      "20000 out of 3583310\n",
      "30000 out of 3583310\n",
      "40000 out of 3583310\n",
      "50000 out of 3583310\n",
      "60000 out of 3583310\n",
      "70000 out of 3583310\n",
      "80000 out of 3583310\n",
      "90000 out of 3583310\n",
      "100000 out of 3583310\n",
      "110000 out of 3583310\n",
      "120000 out of 3583310\n",
      "130000 out of 3583310\n",
      "140000 out of 3583310\n",
      "150000 out of 3583310\n",
      "160000 out of 3583310\n",
      "170000 out of 3583310\n",
      "180000 out of 3583310\n",
      "190000 out of 3583310\n",
      "200000 out of 3583310\n",
      "210000 out of 3583310\n",
      "220000 out of 3583310\n",
      "230000 out of 3583310\n",
      "240000 out of 3583310\n",
      "250000 out of 3583310\n",
      "260000 out of 3583310\n",
      "270000 out of 3583310\n",
      "280000 out of 3583310\n",
      "290000 out of 3583310\n",
      "300000 out of 3583310\n",
      "310000 out of 3583310\n",
      "320000 out of 3583310\n",
      "330000 out of 3583310\n",
      "340000 out of 3583310\n",
      "350000 out of 3583310\n",
      "360000 out of 3583310\n",
      "370000 out of 3583310\n",
      "380000 out of 3583310\n",
      "390000 out of 3583310\n",
      "400000 out of 3583310\n",
      "410000 out of 3583310\n",
      "420000 out of 3583310\n",
      "430000 out of 3583310\n",
      "440000 out of 3583310\n",
      "450000 out of 3583310\n",
      "460000 out of 3583310\n",
      "470000 out of 3583310\n",
      "480000 out of 3583310\n",
      "490000 out of 3583310\n",
      "500000 out of 3583310\n",
      "510000 out of 3583310\n",
      "520000 out of 3583310\n",
      "530000 out of 3583310\n",
      "540000 out of 3583310\n",
      "550000 out of 3583310\n",
      "560000 out of 3583310\n",
      "570000 out of 3583310\n",
      "580000 out of 3583310\n",
      "590000 out of 3583310\n",
      "600000 out of 3583310\n",
      "610000 out of 3583310\n",
      "620000 out of 3583310\n",
      "630000 out of 3583310\n",
      "640000 out of 3583310\n",
      "650000 out of 3583310\n",
      "660000 out of 3583310\n",
      "670000 out of 3583310\n",
      "680000 out of 3583310\n",
      "690000 out of 3583310\n",
      "700000 out of 3583310\n",
      "710000 out of 3583310\n",
      "720000 out of 3583310\n",
      "730000 out of 3583310\n",
      "740000 out of 3583310\n",
      "750000 out of 3583310\n",
      "760000 out of 3583310\n",
      "770000 out of 3583310\n",
      "780000 out of 3583310\n",
      "790000 out of 3583310\n",
      "800000 out of 3583310\n",
      "810000 out of 3583310\n",
      "820000 out of 3583310\n",
      "830000 out of 3583310\n",
      "840000 out of 3583310\n",
      "850000 out of 3583310\n",
      "860000 out of 3583310\n",
      "870000 out of 3583310\n",
      "880000 out of 3583310\n",
      "890000 out of 3583310\n",
      "900000 out of 3583310\n",
      "910000 out of 3583310\n",
      "920000 out of 3583310\n",
      "930000 out of 3583310\n",
      "940000 out of 3583310\n",
      "950000 out of 3583310\n",
      "960000 out of 3583310\n",
      "970000 out of 3583310\n",
      "980000 out of 3583310\n",
      "990000 out of 3583310\n",
      "1000000 out of 3583310\n",
      "1010000 out of 3583310\n",
      "1020000 out of 3583310\n",
      "1030000 out of 3583310\n",
      "1040000 out of 3583310\n",
      "1050000 out of 3583310\n",
      "1060000 out of 3583310\n",
      "1070000 out of 3583310\n",
      "1080000 out of 3583310\n",
      "1090000 out of 3583310\n",
      "1100000 out of 3583310\n",
      "1110000 out of 3583310\n",
      "1120000 out of 3583310\n",
      "1130000 out of 3583310\n",
      "1140000 out of 3583310\n",
      "1150000 out of 3583310\n",
      "1160000 out of 3583310\n",
      "1170000 out of 3583310\n",
      "1180000 out of 3583310\n",
      "1190000 out of 3583310\n",
      "1200000 out of 3583310\n",
      "1210000 out of 3583310\n",
      "1220000 out of 3583310\n",
      "1230000 out of 3583310\n",
      "1240000 out of 3583310\n",
      "1250000 out of 3583310\n",
      "1260000 out of 3583310\n",
      "1270000 out of 3583310\n",
      "1280000 out of 3583310\n",
      "1290000 out of 3583310\n",
      "1300000 out of 3583310\n",
      "1310000 out of 3583310\n",
      "1320000 out of 3583310\n",
      "1330000 out of 3583310\n",
      "1340000 out of 3583310\n",
      "1350000 out of 3583310\n",
      "1360000 out of 3583310\n",
      "1370000 out of 3583310\n",
      "1380000 out of 3583310\n",
      "1390000 out of 3583310\n",
      "1400000 out of 3583310\n",
      "1410000 out of 3583310\n",
      "1420000 out of 3583310\n",
      "1430000 out of 3583310\n",
      "1440000 out of 3583310\n",
      "1450000 out of 3583310\n",
      "1460000 out of 3583310\n",
      "1470000 out of 3583310\n",
      "1480000 out of 3583310\n",
      "1490000 out of 3583310\n",
      "1500000 out of 3583310\n",
      "1510000 out of 3583310\n",
      "1520000 out of 3583310\n",
      "1530000 out of 3583310\n",
      "1540000 out of 3583310\n",
      "1550000 out of 3583310\n",
      "1560000 out of 3583310\n",
      "1570000 out of 3583310\n",
      "1580000 out of 3583310\n",
      "1590000 out of 3583310\n",
      "1600000 out of 3583310\n",
      "1610000 out of 3583310\n",
      "1620000 out of 3583310\n",
      "1630000 out of 3583310\n",
      "1640000 out of 3583310\n",
      "1650000 out of 3583310\n",
      "1660000 out of 3583310\n",
      "1670000 out of 3583310\n",
      "1680000 out of 3583310\n",
      "1690000 out of 3583310\n",
      "1700000 out of 3583310\n",
      "1710000 out of 3583310\n",
      "1720000 out of 3583310\n",
      "1730000 out of 3583310\n",
      "1740000 out of 3583310\n",
      "1750000 out of 3583310\n",
      "1760000 out of 3583310\n",
      "1770000 out of 3583310\n",
      "1780000 out of 3583310\n",
      "1790000 out of 3583310\n",
      "1800000 out of 3583310\n",
      "1810000 out of 3583310\n",
      "1820000 out of 3583310\n",
      "1830000 out of 3583310\n",
      "1840000 out of 3583310\n",
      "1850000 out of 3583310\n",
      "1860000 out of 3583310\n",
      "1870000 out of 3583310\n",
      "1880000 out of 3583310\n",
      "1890000 out of 3583310\n",
      "1900000 out of 3583310\n",
      "1910000 out of 3583310\n",
      "1920000 out of 3583310\n",
      "1930000 out of 3583310\n",
      "1940000 out of 3583310\n",
      "1950000 out of 3583310\n",
      "1960000 out of 3583310\n",
      "1970000 out of 3583310\n",
      "1980000 out of 3583310\n",
      "1990000 out of 3583310\n",
      "2000000 out of 3583310\n",
      "2010000 out of 3583310\n",
      "2020000 out of 3583310\n",
      "2030000 out of 3583310\n",
      "2040000 out of 3583310\n",
      "2050000 out of 3583310\n",
      "2060000 out of 3583310\n",
      "2070000 out of 3583310\n",
      "2080000 out of 3583310\n",
      "2090000 out of 3583310\n",
      "2100000 out of 3583310\n",
      "2110000 out of 3583310\n",
      "2120000 out of 3583310\n",
      "2130000 out of 3583310\n",
      "2140000 out of 3583310\n",
      "2150000 out of 3583310\n",
      "2160000 out of 3583310\n",
      "2170000 out of 3583310\n",
      "2180000 out of 3583310\n",
      "2190000 out of 3583310\n",
      "2200000 out of 3583310\n",
      "2210000 out of 3583310\n",
      "2220000 out of 3583310\n",
      "2230000 out of 3583310\n",
      "2240000 out of 3583310\n",
      "2250000 out of 3583310\n",
      "2260000 out of 3583310\n",
      "2270000 out of 3583310\n",
      "2280000 out of 3583310\n",
      "2290000 out of 3583310\n",
      "2300000 out of 3583310\n",
      "2310000 out of 3583310\n",
      "2320000 out of 3583310\n",
      "2330000 out of 3583310\n",
      "2340000 out of 3583310\n",
      "2350000 out of 3583310\n",
      "2360000 out of 3583310\n",
      "2370000 out of 3583310\n",
      "2380000 out of 3583310\n",
      "2390000 out of 3583310\n",
      "2400000 out of 3583310\n",
      "2410000 out of 3583310\n",
      "2420000 out of 3583310\n",
      "2430000 out of 3583310\n",
      "2440000 out of 3583310\n",
      "2450000 out of 3583310\n",
      "2460000 out of 3583310\n",
      "2470000 out of 3583310\n",
      "2480000 out of 3583310\n",
      "2490000 out of 3583310\n",
      "2500000 out of 3583310\n",
      "2510000 out of 3583310\n",
      "2520000 out of 3583310\n",
      "2530000 out of 3583310\n",
      "2540000 out of 3583310\n",
      "2550000 out of 3583310\n",
      "2560000 out of 3583310\n",
      "2570000 out of 3583310\n",
      "2580000 out of 3583310\n",
      "2590000 out of 3583310\n",
      "2600000 out of 3583310\n",
      "2610000 out of 3583310\n",
      "2620000 out of 3583310\n",
      "2630000 out of 3583310\n",
      "2640000 out of 3583310\n",
      "2650000 out of 3583310\n",
      "2660000 out of 3583310\n",
      "2670000 out of 3583310\n",
      "2680000 out of 3583310\n",
      "2690000 out of 3583310\n",
      "2700000 out of 3583310\n",
      "2710000 out of 3583310\n",
      "2720000 out of 3583310\n",
      "2730000 out of 3583310\n",
      "2740000 out of 3583310\n",
      "2750000 out of 3583310\n",
      "2760000 out of 3583310\n",
      "2770000 out of 3583310\n",
      "2780000 out of 3583310\n",
      "2790000 out of 3583310\n",
      "2800000 out of 3583310\n",
      "2810000 out of 3583310\n",
      "2820000 out of 3583310\n",
      "2830000 out of 3583310\n",
      "2840000 out of 3583310\n",
      "2850000 out of 3583310\n",
      "2860000 out of 3583310\n",
      "2870000 out of 3583310\n",
      "2880000 out of 3583310\n",
      "2890000 out of 3583310\n",
      "2900000 out of 3583310\n",
      "2910000 out of 3583310\n",
      "2920000 out of 3583310\n",
      "2930000 out of 3583310\n",
      "2940000 out of 3583310\n",
      "2950000 out of 3583310\n",
      "2960000 out of 3583310\n",
      "2970000 out of 3583310\n",
      "2980000 out of 3583310\n",
      "2990000 out of 3583310\n",
      "3000000 out of 3583310\n",
      "3010000 out of 3583310\n",
      "3020000 out of 3583310\n",
      "3030000 out of 3583310\n",
      "3040000 out of 3583310\n",
      "3050000 out of 3583310\n",
      "3060000 out of 3583310\n",
      "3070000 out of 3583310\n",
      "3080000 out of 3583310\n",
      "3090000 out of 3583310\n",
      "3100000 out of 3583310\n",
      "3110000 out of 3583310\n",
      "3120000 out of 3583310\n",
      "3130000 out of 3583310\n",
      "3140000 out of 3583310\n",
      "3150000 out of 3583310\n",
      "3160000 out of 3583310\n",
      "3170000 out of 3583310\n",
      "3180000 out of 3583310\n",
      "3190000 out of 3583310\n",
      "3200000 out of 3583310\n",
      "3210000 out of 3583310\n",
      "3220000 out of 3583310\n",
      "3230000 out of 3583310\n",
      "3240000 out of 3583310\n",
      "3250000 out of 3583310\n",
      "3260000 out of 3583310\n",
      "3270000 out of 3583310\n",
      "3280000 out of 3583310\n",
      "3290000 out of 3583310\n",
      "3300000 out of 3583310\n",
      "3310000 out of 3583310\n",
      "3320000 out of 3583310\n",
      "3330000 out of 3583310\n",
      "3340000 out of 3583310\n",
      "3350000 out of 3583310\n",
      "3360000 out of 3583310\n",
      "3370000 out of 3583310\n",
      "3380000 out of 3583310\n",
      "3390000 out of 3583310\n",
      "3400000 out of 3583310\n",
      "3410000 out of 3583310\n",
      "3420000 out of 3583310\n",
      "3430000 out of 3583310\n",
      "3440000 out of 3583310\n",
      "3450000 out of 3583310\n",
      "3460000 out of 3583310\n",
      "3470000 out of 3583310\n",
      "3480000 out of 3583310\n",
      "3490000 out of 3583310\n",
      "3500000 out of 3583310\n",
      "3510000 out of 3583310\n",
      "3520000 out of 3583310\n",
      "3530000 out of 3583310\n",
      "3540000 out of 3583310\n",
      "3550000 out of 3583310\n",
      "3560000 out of 3583310\n",
      "3570000 out of 3583310\n",
      "3580000 out of 3583310\n"
     ]
    }
   ],
   "source": [
    "dicts = compute_keywords_of_complete_visit(5, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ids_keywords_weights.json', 'w') as outfile:\n",
    "    json.dump(dicts, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
