{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "180cc168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import string\n",
    "import re\n",
    "import gensim.models\n",
    "import tempfile\n",
    "from gensim.models import Word2Vec\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539562c0",
   "metadata": {},
   "source": [
    "# Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e768ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_stopwords = False\n",
    "filter_pronouns = False\n",
    "\n",
    "# Reading in our sentences from the scrape results\n",
    "matthew = False\n",
    "path = \"C:/Users/laure/OneDrive/Documenten/Project 3.1 APG Files/\"\n",
    "filename = 'public_and_private_sentences_filtered.csv'\n",
    "if matthew:\n",
    "    df = pd.read_csv('DATA/scrape_results/' + filename)\n",
    "else:\n",
    "    df = pd.read_csv(path + filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e62793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to list\n",
    "corpus = df['sentences'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd6c687",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m sentences \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sentence \u001B[38;5;129;01min\u001B[39;00m corpus:\n\u001B[1;32m----> 4\u001B[0m     sentences\u001B[38;5;241m.\u001B[39mappend(\u001B[43msentence\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'float' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "# Break each sentence into list of individual words\n",
    "sentences = []\n",
    "for sentence in corpus:\n",
    "    sentences.append(sentence.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom word2vec model with given parameters (from internet)\n",
    "custom_model = Word2Vec(window = 10, workers = 20, negative = 5, sample = 1e-5)\n",
    "\n",
    "# Build the vocab by giving the sentences\n",
    "custom_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "# Train the model on the inputted sentences, epoch = 50, higher epochs give better output but increase time\n",
    "start = time.time()\n",
    "custom_model.train(sentences, total_examples=custom_model.corpus_count, epochs=50, report_delay=1)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Time elapsed (seconds): \" + str(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f1b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for re-use\n",
    "filename = 'custom_model_sentences_filtered.wordvectors'\n",
    "if matthew:\n",
    "    custom_model.save('DATA/Data/' + filename)\n",
    "else:\n",
    "    custom_model.save(path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c97d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some small tests\n",
    "number_of_words = str(len(custom_model.wv))\n",
    "print('Number of words: ' + number_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6215b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see what words are similar to pensioen\n",
    "most_similar_to_pensioen = custom_model.wv.most_similar(positive='pensioen')\n",
    "print(\"Words most similar to pensioen: \", most_similar_to_pensioen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(path + 'models/model.bin', binary=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(model.similarity('pensioen', 'aow'))\n",
    "model.most_similar(positive='pensioen')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Comparing the Word2vec model trained on ABP's scrape results with the Word2vec model that is downloaded from [insert link]."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Since the two models are created separately, the geometric positions of the embeddings in vector space are not directly comparable.\n",
    "# To compare the embeddings, we first have to align the embeddings. The method 'align_embeddings' performs this alignment.\n",
    "\n",
    "\n",
    "def align_embeddings(model1, model2):\n",
    "    # Retrieving the common vocabulary.\n",
    "    vocabulary1 = set(model1.wv.index_to_key)\n",
    "    vocabulary2 = set(model2.index_to_key)\n",
    "    common_vocabulary = vocabulary1 & vocabulary2\n",
    "\n",
    "    # Extracting the word vectors from each model of the common vocabulary\n",
    "    vectors1 = model1.wv[common_vocabulary]\n",
    "    vectors2 = model2[common_vocabulary]\n",
    "\n",
    "    # Computing and subtracting the average vectors.\n",
    "    average1 = np.mean(vectors1, axis=0)\n",
    "    average2 = np.mean(vectors2, axis=0)\n",
    "    vectors1 = vectors1 - average1\n",
    "    vectors2 = vectors2 - average2\n",
    "\n",
    "    # Computing the matrix of dot products.\n",
    "    dot_product = np.dot(vectors1.T, vectors2)\n",
    "\n",
    "    # Using Singular Value Decomposition (SVD) to find the rotation matrix.\n",
    "    U, s, Vt = np.linalg.svd(dot_product)\n",
    "\n",
    "    # Using the rotation matrix to rotate the word vectors of 'model1' and re-averaging the word vectors to transform them back to the original space.\n",
    "    rotated_vectors1 = np.dot(vectors2, U)\n",
    "    rotated_vectors1 += average1\n",
    "\n",
    "    # Using these rotated vectors, a new Word2Vec model can be created.\n",
    "    aligned_model1 = Word2Vec(sentences=None, min_count=1)\n",
    "    aligned_model1.build_vocab([common_vocabulary])\n",
    "    aligned_model1.wv.vectors = rotated_vectors1\n",
    "    #aligned_model1.train(common_vocabulary, total_examples=custom_model.corpus_count, epochs=50, report_delay=1)\n",
    "\n",
    "    return aligned_model1\n",
    "\n",
    "aligned_custom_model = align_embeddings(custom_model, model)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "most_similar_to_pensioen_aligned = aligned_custom_model.wv.most_similar(positive='pensioen', topn=100)\n",
    "print(\"Words most similar to pensioen: \", most_similar_to_pensioen_aligned)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "aaaa = Word2Vec.load(path + \"custom_model_none_filtered.bin\")\n",
    "aa = KeyedVectors.load_word2vec_format(path + \"custom_model_none_filtered.bin\", binary=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}