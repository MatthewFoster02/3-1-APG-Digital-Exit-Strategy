{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Change this variable and the path in the else statement below.\n",
    "laurence = False;\n",
    "\n",
    "if laurence:\n",
    "    path = \"C:/Users/laure/OneDrive/Documenten/Project 3.1 APG Files/\";\n",
    "else:\n",
    "    path = 'C:/Users/01din/Desktop/data APG/tfidf/weighted_tfidf/';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# # Download files\n",
    "# private_scrape = pd.read_excel(path + \"private_scrape_results.xlsx\");\n",
    "# public_scrape = pd.read_excel(path + \"public_scrape_results.xlsx\");\n",
    "tf_idf_non_weighted = pd.read_csv(path + \"tf_idf_new.csv\");\n",
    "tf_idf_keywords = pd.read_csv(path + \"tf_idf_keywords_new.csv\");\n",
    "all_data = pd.read_csv(path + \"allDataOneFile.csv\", usecols=['page_url_id', 'seconds_spent']);\n",
    "url_references = pd.read_csv(path + \"url_references_reduced.csv\");"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# Storing all of the records of 'public_scrape' in English in a separate dataframe. 'private_scrape' does not contain any records in\n",
    "# English so this is not needed there.\n",
    "# public_scrape_english = public_scrape.loc[public_scrape['full_url'].str.contains(\"english\", case=False)]\n",
    "#\n",
    "# Storing all of the records of 'public_scrape' in Dutch in a separate dataframe.\n",
    "# public_scrape_dutch = public_scrape.loc[~public_scrape['full_url'].str.contains(\"english\", case=False)]\n",
    "\n",
    "# Obtaining the paragraphs of these scrape results and converting them to lists, making them easier to iterare over.\n",
    "# private_corpus = private_scrape.urls.tolist()\n",
    "# public_corpus = public_scrape_dutch.full_url.tolist()\n",
    "# public_corpus_english = public_scrape_english.full_url.tolist()\n",
    "#\n",
    "# # Adding the 'private_corpus' and 'public_corpus' as they are both in Dutch.\n",
    "# corpus_dutch = public_corpus + private_corpus\n",
    "# corpus_english = public_corpus_english\n",
    "\n",
    "corpus = pd.read_csv('C:/Users/01din/Desktop/data APG/FIXED_SCRAPES/url_references_with_paragraphs_no_english.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# sum_of_total_time = 0\n",
    "#\n",
    "# for i in range(len(corpus)):\n",
    "#     url_id = url_references.index[url_references['urls'] == corpus[i]].tolist()[0] + 1;\n",
    "#     indices_in_all_data = all_data.index[all_data['page_url_id'] == url_id].tolist();\n",
    "#     time = 0;\n",
    "#     for j in range(len(indices_in_all_data)):\n",
    "#         time += all_data['seconds_spent'].iloc[indices_in_all_data[j]];\n",
    "#     sum_of_total_time += time;\n",
    "# print(sum_of_total_time)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only compare identically-labeled Series objects",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [58], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(corpus)):\n\u001B[0;32m      9\u001B[0m     url_id \u001B[38;5;241m=\u001B[39m corpus\u001B[38;5;241m.\u001B[39miloc[i]\n\u001B[1;32m---> 10\u001B[0m     indices_in_all_data \u001B[38;5;241m=\u001B[39m all_data\u001B[38;5;241m.\u001B[39mindex[\u001B[43mall_data\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpage_url_id\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m==\u001B[39;49m\u001B[43m \u001B[49m\u001B[43murl_id\u001B[49m]\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[0;32m     11\u001B[0m     time \u001B[38;5;241m=\u001B[39m all_data\u001B[38;5;241m.\u001B[39mloc[indices_in_all_data, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mseconds_spent\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39msum()\n\u001B[0;32m     12\u001B[0m     weight \u001B[38;5;241m=\u001B[39m time \u001B[38;5;241m/\u001B[39m sum_of_total_time\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001B[0m, in \u001B[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m     68\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m\n\u001B[0;32m     70\u001B[0m other \u001B[38;5;241m=\u001B[39m item_from_zerodim(other)\n\u001B[1;32m---> 72\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\arraylike.py:42\u001B[0m, in \u001B[0;36mOpsMixin.__eq__\u001B[1;34m(self, other)\u001B[0m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;129m@unpack_zerodim_and_defer\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__eq__\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__eq__\u001B[39m(\u001B[38;5;28mself\u001B[39m, other):\n\u001B[1;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cmp_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moperator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43meq\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\series.py:6237\u001B[0m, in \u001B[0;36mSeries._cmp_method\u001B[1;34m(self, other, op)\u001B[0m\n\u001B[0;32m   6234\u001B[0m res_name \u001B[38;5;241m=\u001B[39m ops\u001B[38;5;241m.\u001B[39mget_op_result_name(\u001B[38;5;28mself\u001B[39m, other)\n\u001B[0;32m   6236\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(other, Series) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indexed_same(other):\n\u001B[1;32m-> 6237\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan only compare identically-labeled Series objects\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6239\u001B[0m lvalues \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m   6240\u001B[0m rvalues \u001B[38;5;241m=\u001B[39m extract_array(other, extract_numpy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, extract_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[1;31mValueError\u001B[0m: Can only compare identically-labeled Series objects"
     ]
    }
   ],
   "source": [
    "import time as tm\n",
    "import numpy as np\n",
    "\n",
    "sum_of_total_time = 1494220512\n",
    "\n",
    "tf_idf_time_weighted = tf_idf_non_weighted.copy()\n",
    "\n",
    "for i in range(len(corpus)):\n",
    "    url_id = corpus.iloc[i]\n",
    "    indices_in_all_data = all_data.index[all_data['page_url_id'] == url_id].tolist()\n",
    "    time = all_data.loc[indices_in_all_data, 'seconds_spent'].sum()\n",
    "    weight = time / sum_of_total_time\n",
    "    tf_idf_time_weighted.iloc[i, :] = tf_idf_time_weighted.iloc[i, :] * weight\n",
    "    print(i)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf_idf_time_weighted = tf_idf_time_weighted.iloc[: , 1:]\n",
    "tf_idf_time_weighted.to_csv(path + \"tf_idf_time_weighted.csv\");"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
