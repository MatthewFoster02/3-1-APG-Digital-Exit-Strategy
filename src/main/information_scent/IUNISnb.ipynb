{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class ProximalCues:\n",
    "    def __init__(self):\n",
    "        generic = lambda x: literal_eval(x)\n",
    "\n",
    "        conv = {'pc': generic}\n",
    "\n",
    "        self.urls = pd.read_csv(\"../data/urls/url-reference_new.csv\", converters=conv)\n",
    "\n",
    "    # Get the proximal cues by page id\n",
    "    def get_proximal_cues_by_id(self, id):\n",
    "        return self.urls.loc[self.urls.id==id].pc.iloc[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class TfIdf:\n",
    "    def __init__(self):\n",
    "        # Loading in the tf-idf\n",
    "        # Rows are documents, the first column is the document id\n",
    "        # Columns are keywords, the first row is the keyword id\n",
    "        self.tfidf = pd.read_csv(\"../data/tf_idf/tf_idf.csv\")\n",
    "\n",
    "        # Loading in the keywords\n",
    "        # Two columns, column 1 is id, column 2 is keyword\n",
    "        # We can access the weight in the tf-idf by first accessing the id number from the keyword file\n",
    "        self.tfidf_keywords = pd.read_csv(\"../data/tf_idf/tf_idf_keywords.csv\")\n",
    "        self.tfidf_keywords.columns = [\"id\", \"keyword\"]\n",
    "\n",
    "    def get_id_by_keyword(self, keyword):\n",
    "        return self.tfidf_keywords.id.iloc[self.tfidf_keywords[self.tfidf_keywords.keyword == keyword].index].values[0]\n",
    "\n",
    "\n",
    "    def get_keyword_by_id(self, id):\n",
    "        return self.tfidf_keywords.loc[self.tfidf_keywords.id==id, 'keyword'].iloc[0]\n",
    "    # Method to get the tfidf value of a keyword in a page\n",
    "    def get_tf_idf_value(self, page_id, keyword):\n",
    "        keyword_id = self.get_id_by_keyword(keyword)\n",
    "        return self.tfidf.iloc[page_id, keyword_id + 1]\n",
    "\n",
    "    def get_all_keywords_by_id(self, page_id):\n",
    "        keywords = self.tfidf.iloc[page_id][1:].values\n",
    "        return keywords\n",
    "\n",
    "    def get_all_keywords_by_id_normalized(self, page_id):\n",
    "        keywords_weights = self.get_all_keywords_by_id(page_id)\n",
    "        sum_value = sum(keywords_weights)\n",
    "        keywords_weights_normalized = keywords_weights/sum_value\n",
    "        return keywords_weights_normalized\n",
    "\n",
    "    def get_number_of_keywords(self):\n",
    "        return self.tfidf_keywords.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class AdjacencyMatrix:\n",
    "    def __init__(self):\n",
    "        # Loading in the adjacency matrix\n",
    "        # First column and row are data immediately, so access directly by page id\n",
    "        # If row(page_id_1) leads to column(page_id_2) = 1 else = 0\n",
    "        self.adjacency_matrix = pd.read_csv(\"../data/matrices/adjacency_matrix.csv\", header=None)\n",
    "\n",
    "    # Method to get the adjacency value from two page ids\n",
    "    def get_adjacency_value(self, page_id_1, page_id_2):\n",
    "        return self.adjacency_matrix.iloc[page_id_1, page_id_2] == 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "adjacency_matrix = AdjacencyMatrix()\n",
    "proximal_cues = ProximalCues()\n",
    "tfidf = TfIdf()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "generic = lambda x: literal_eval(x)\n",
    "\n",
    "conv = {'url_id_path': generic,\n",
    "        'seconds_spent_path': generic}\n",
    "df = pd.read_csv('../data/clickdata/dataNoUnscrapedVisitsOrUnder20Sec.csv', converters=conv)\n",
    "\n",
    "paths = df.url_id_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I took the liberty to implement my own - perhaps but not necessarily slightly simplified - version of IUNIS.\n",
    "\n",
    "Input is the ordered list of page id's that the user has visited.\n",
    "For each page, take the TF-IDF values from that page, which is a row of keywords, with either 0 if the keyword is not present or 0<value<=1 if it is.\n",
    "\n",
    "Then, for each next page, we add the TF-IDF values onto the existing weights.\n",
    "\n",
    "Eventually we can sort the list and we will have the keywords with the highest weight on top."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "def find_keyword_weights(path):\n",
    "    weights = np.zeros(tfidf.get_number_of_keywords())\n",
    "    pd.options.display.max_rows = 0\n",
    "    for id in path:\n",
    "        weights += tfidf.get_all_keywords_by_id_normalized(id)\n",
    "\n",
    "    df = DataFrame(weights, columns=['weights'])\n",
    "    return df.sort_values(by=['weights'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this model, I introduced a factor of decay. Essentially, every iteration, all values are divided by 1.25, meaning that recent keywords are more biased.\n",
    "This is a very simple implementation, we can experiment with changing this 1.25, and also look at different implementations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_keyword_weights_more_weight_on_recent_pages(path):\n",
    "    weights = np.zeros(tfidf.get_number_of_keywords())\n",
    "    pd.options.display.max_rows = 0\n",
    "    for id in path:\n",
    "        weights = weights/1.25\n",
    "        weights += tfidf.get_all_keywords_by_id_normalized(id)\n",
    "\n",
    "    df = DataFrame(weights, columns=['weights'])\n",
    "    return df.sort_values(by=['weights'], ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a method to print out the top 'num_of_words' weighted keywords."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def print_top_weights_as_words(num_of_words, weights):\n",
    "    top_weights = weights.head(num_of_words)\n",
    "    i=0\n",
    "    for index in top_weights.index:\n",
    "        print(str(tfidf.get_keyword_by_id(index)) + \" : \" + str(top_weights.weights.iloc[i]))\n",
    "        i+=1\n",
    "    print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Line 2 in this section gets rid of all useless pages (login, logout, search, and error)\n",
    "Then, if the user has visited more than 5 pages, it will compute the keywords up until page 5."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for path in paths:\n",
    "    path[:] = [x for x in path if x < 1556]\n",
    "    if len(path)>5:\n",
    "        path[:] = path[:5]\n",
    "        print_top_weights_as_words(10, find_keyword_weights(path))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "These sections computes the weights after each different page to see how it changes throughout the visit\n",
    "We can do interesting experiments to see how information need changes throughout the visit, and to find out at which page index we can best make our prediction final"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188, 228, 3, 1, 12, 7, 20, 1, 7, 1, 12, 7, 13, 188, 1]\n"
     ]
    }
   ],
   "source": [
    "path = paths[12]\n",
    "path[:] = [x for x in path if x < 1556]\n",
    "print(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bijverdienen : 0.0838899052653509\n",
      "gekregen : 0.07342690609120023\n",
      "jaaropgave : 0.0723186300120255\n",
      "betaalspecificatie : 0.06883927120918737\n",
      "nabetaling : 0.06679300958519852\n",
      "buitenland : 0.045383799679589665\n",
      "dekkingsgraad : 0.04179540235127088\n",
      "speciaal : 0.03628136290531201\n",
      "uitbetaling : 0.03617637516726869\n",
      "betaaldatums : 0.030811020135422404\n",
      "\n",
      "\n",
      "nabestaande : 0.1296809887240472\n",
      "nabestaandenpensioen : 0.10169550611141687\n",
      "verander : 0.0736911189788815\n",
      "bijverdienen : 0.06711192421228071\n",
      "gekregen : 0.05874152487296018\n",
      "jaaropgave : 0.0578549040096204\n",
      "betaalspecificatie : 0.05507141696734989\n",
      "nabetaling : 0.05343440766815881\n",
      "verhoog : 0.052034322325171\n",
      "regel : 0.04864181290583492\n",
      "\n",
      "\n",
      "nabestaandenpensioen : 0.13035720664520836\n",
      "samenvatting : 0.10899552751594592\n",
      "kiezen : 0.10773159420182397\n",
      "nabestaande : 0.10374479097923776\n",
      "samenstellen : 0.10293099656999839\n",
      "ineen : 0.084933645432089\n",
      "deeltijdpensioen : 0.08270564389222383\n",
      "loonheffingskorting : 0.07826937410655303\n",
      "aanpassen : 0.07525841345119526\n",
      "pensioenleeftijd : 0.06767518525248979\n",
      "\n",
      "\n",
      "laxxxxxxxxx : 0.428532850054372\n",
      "dhr : 0.37064414251103606\n",
      "mijnabp : 0.20082300743459183\n",
      "nabestaandenpensioen : 0.10428576531616669\n",
      "samenvatting : 0.08719642201275674\n",
      "kiezen : 0.08618527536145917\n",
      "nabestaande : 0.0829958327833902\n",
      "samenstellen : 0.08234479725599872\n",
      "ineen : 0.06794691634567121\n",
      "deeltijdpensioen : 0.06616451511377906\n",
      "\n",
      "\n",
      "bericht : 1.0\n",
      "laxxxxxxxxx : 0.34282628004349763\n",
      "dhr : 0.29651531400882886\n",
      "mijnabp : 0.16065840594767347\n",
      "nabestaandenpensioen : 0.08342861225293335\n",
      "samenvatting : 0.06975713761020538\n",
      "kiezen : 0.06894822028916733\n",
      "nabestaande : 0.06639666622671217\n",
      "samenstellen : 0.06587583780479897\n",
      "ineen : 0.05435753307653697\n",
      "\n",
      "\n",
      "bericht : 0.8\n",
      "laxxxxxxxxx : 0.7027938740891702\n",
      "dhr : 0.6078563937180992\n",
      "mijnabp : 0.3293497321927306\n",
      "nabestaandenpensioen : 0.06674288980234669\n",
      "samenvatting : 0.055805710088164304\n",
      "kiezen : 0.05515857623133387\n",
      "nabestaande : 0.05311733298136974\n",
      "samenstellen : 0.052700670243839176\n",
      "ineen : 0.04348602646122958\n",
      "\n",
      "\n",
      "bericht : 0.6591061438298365\n",
      "laxxxxxxxxx : 0.5622350992713361\n",
      "dhr : 0.513412316634651\n",
      "mijnabp : 0.2634797857541845\n",
      "sessie : 0.061652467180624136\n",
      "nabestaandenpensioen : 0.05339431184187735\n",
      "samenvatting : 0.044644568070531444\n",
      "kiezen : 0.044126860985067094\n",
      "nabestaande : 0.042493866385095794\n",
      "samenstellen : 0.04216053619507134\n",
      "\n",
      "\n",
      "laxxxxxxxxx : 0.8783209294714409\n",
      "dhr : 0.7813739958187569\n",
      "bericht : 0.5272849150638692\n",
      "mijnabp : 0.41160683603793946\n",
      "sessie : 0.04932197374449931\n",
      "nabestaandenpensioen : 0.04271544947350188\n",
      "samenvatting : 0.035715654456425154\n",
      "kiezen : 0.03530148878805368\n",
      "nabestaande : 0.033995093108076635\n",
      "samenstellen : 0.03372842895605707\n",
      "\n",
      "\n",
      "laxxxxxxxxx : 1.1311895936315248\n",
      "dhr : 0.9957433391660415\n",
      "mijnabp : 0.5301084762649434\n",
      "bericht : 0.42182793205109537\n",
      "sessie : 0.03945757899559944\n",
      "nabestaandenpensioen : 0.034172359578801506\n",
      "samenvatting : 0.028572523565140125\n",
      "kiezen : 0.028241191030442942\n",
      "nabestaande : 0.02719607448646131\n",
      "samenstellen : 0.026982743164845658\n",
      "\n",
      "\n",
      "laxxxxxxxxx : 1.333484524959592\n",
      "dhr : 1.1672388138438694\n",
      "mijnabp : 0.6249097884465465\n",
      "bericht : 0.3374623456408763\n",
      "sessie : 0.03156606319647955\n",
      "nabestaandenpensioen : 0.027337887663041203\n",
      "samenvatting : 0.0228580188521121\n",
      "kiezen : 0.022592952824354355\n",
      "nabestaande : 0.021756859589169047\n",
      "samenstellen : 0.021586194531876525\n",
      "\n",
      "\n",
      "bericht : 1.269969876512701\n",
      "laxxxxxxxxx : 1.0667876199676736\n",
      "dhr : 0.9337910510750955\n",
      "mijnabp : 0.49992783075723723\n",
      "sessie : 0.025252850557183643\n",
      "nabestaandenpensioen : 0.021870310130432963\n",
      "samenvatting : 0.01828641508168968\n",
      "kiezen : 0.018074362259483483\n",
      "nabestaande : 0.017405487671335238\n",
      "samenstellen : 0.01726895562550122\n",
      "\n",
      "\n",
      "laxxxxxxxxx : 1.281962946028511\n",
      "dhr : 1.1176769833711124\n",
      "bericht : 1.0159759012101608\n",
      "mijnabp : 0.6007652720403817\n",
      "sessie : 0.020202280445746915\n",
      "nabestaandenpensioen : 0.01749624810434637\n",
      "samenvatting : 0.014629132065351744\n",
      "kiezen : 0.014459489807586786\n",
      "nabestaande : 0.01392439013706819\n",
      "samenstellen : 0.013815164500400975\n",
      "\n",
      "\n",
      "laxxxxxxxxx : 1.0255703568228087\n",
      "dhr : 0.8941415866968899\n",
      "bericht : 0.8127807209681286\n",
      "mijnabp : 0.4806122176323053\n",
      "samenstellen : 0.15820124333138533\n",
      "aow : 0.15353037277137443\n",
      "netto : 0.11649741024536589\n",
      "tegelijk : 0.11236590312250572\n",
      "plan : 0.09944135060531437\n",
      "geniet : 0.09474545334944047\n",
      "\n",
      "\n",
      "laxxxxxxxxx : 0.820456285458247\n",
      "dhr : 0.7153132693575119\n",
      "bericht : 0.6502245767745028\n",
      "mijnabp : 0.3844897741058443\n",
      "samenstellen : 0.12656099466510826\n",
      "aow : 0.12282429821709955\n",
      "netto : 0.09319792819629272\n",
      "tegelijk : 0.08989272249800458\n",
      "bijverdienen : 0.08850180157996491\n",
      "plan : 0.0795530804842515\n",
      "\n",
      "\n",
      "laxxxxxxxxx : 1.0848978784209695\n",
      "dhr : 0.9428947579970456\n",
      "bericht : 0.5201796614196023\n",
      "mijnabp : 0.5084148267192673\n",
      "samenstellen : 0.1012487957320866\n",
      "aow : 0.09825943857367964\n",
      "netto : 0.07455834255703417\n",
      "tegelijk : 0.07191417799840366\n",
      "bijverdienen : 0.07080144126397193\n",
      "plan : 0.0636424643874012\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(path)):\n",
    "    subpath = path[:i+1]\n",
    "    weights = find_keyword_weights_more_weight_on_recent_pages(subpath)\n",
    "    print_top_weights_as_words(10, weights)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Idea for evaluation:\n",
    "\n",
    "Look at the keywords at a specific time (we must make sure the weights are normalised, they are not in the implementation above), and compare it with a certain page near the end of the user visit to see if the user found their need.\n",
    "We can do either the last page, or maybe the page that the user has spent the most time on.\n",
    "The problem becomes that we want to evaluate the prediction of the information need, and there will be inaccuracies as the user data is not necessarily correct.\n",
    "But if we can create a metric and we can compare different implementations with the same metric we still have something nice.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
