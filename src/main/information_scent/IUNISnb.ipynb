{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "I dislike classes in python but I think it makes sense to make these classes.\n",
    "I would put the adj matrix in the tfidf but that would just create confusion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "outputs": [],
   "source": [
    "class ProximalCues:\n",
    "    def __init__(self):\n",
    "        generic = lambda x: literal_eval(x)\n",
    "\n",
    "        conv = {'pc': generic}\n",
    "\n",
    "        self.urls = pd.read_csv(\"../data/urls/url-reference_new.csv\", converters=conv)\n",
    "\n",
    "    # Get the proximal cues by page id\n",
    "    def get_proximal_cues_by_id(self, id):\n",
    "        return self.urls.loc[self.urls.id==id].pc.iloc[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class TfIdf:\n",
    "    def __init__(self):\n",
    "        # Loading in the tf-idf\n",
    "        # Rows are documents, the first column is the document id\n",
    "        # Columns are keywords, the first row is the keyword id\n",
    "        self.tfidf = pd.read_csv(\"../data/tf_idf/tf_idf.csv\")\n",
    "\n",
    "        # Loading in the keywords\n",
    "        # Two columns, column 1 is id, column 2 is keyword\n",
    "        # We can access the weight in the tf-idf by first accessing the id number from the keyword file\n",
    "        self.tfidf_keywords = pd.read_csv(\"../data/tf_idf/tf_idf_keywords.csv\")\n",
    "        self.tfidf_keywords.columns = [\"id\", \"keyword\"]\n",
    "\n",
    "    def get_id_by_keyword(self, keyword):\n",
    "        return self.tfidf_keywords.id.iloc[self.tfidf_keywords[self.tfidf_keywords.keyword == keyword].index].values[0]\n",
    "\n",
    "    # Method to get the tfidf value of a keyword in a page\n",
    "    def get_tf_idf_value(self, page_id, keyword):\n",
    "        keyword_id = self.get_id_by_keyword(keyword)\n",
    "        return self.tfidf.iloc[page_id, keyword_id + 1]\n",
    "\n",
    "    def get_all_keywords_by_id(self, page_id):\n",
    "        keywords = self.tfidf.iloc[page_id][1:].values\n",
    "        return keywords\n",
    "\n",
    "    def get_all_keywords_by_id_normalized(self, page_id):\n",
    "        keywords_weights = self.get_all_keywords_by_id(page_id)\n",
    "        sum_value = sum(keywords_weights)\n",
    "        keywords_weights_normalized = keywords_weights/sum_value\n",
    "        return keywords_weights_normalized\n",
    "\n",
    "    def get_number_of_keywords(self):\n",
    "        return self.tfidf_keywords.shape[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [],
   "source": [
    "class AdjacencyMatrix:\n",
    "    def __init__(self):\n",
    "        # Loading in the adjacency matrix\n",
    "        # First column and row are data immediately, so access directly by page id\n",
    "        # If row(page_id_1) leads to column(page_id_2) = 1 else = 0\n",
    "        self.adjacency_matrix = pd.read_csv(\"../data/matrices/adjacency_matrix.csv\", header=None)\n",
    "\n",
    "    # Method to get the adjacency value from two page ids\n",
    "    def get_adjacency_value(self, page_id_1, page_id_2):\n",
    "        return self.adjacency_matrix.iloc[page_id_1, page_id_2] == 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "adjacency_matrix = AdjacencyMatrix()\n",
    "proximal_cues = ProximalCues()\n",
    "tfidf = TfIdf()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The input to the model should be a list of documents and the order in which they were visited.\n",
    "Luckily this is exactly what we have."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "generic = lambda x: literal_eval(x)\n",
    "\n",
    "conv = {'url_id_path': generic,\n",
    "        'seconds_spent_path': generic}\n",
    "df = pd.read_csv('../data/clickdata/testGrouped.csv', converters=conv)\n",
    "\n",
    "paths = df.url_id_path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We have one visit path here:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "path = paths[0]\n",
    "path[:] = [x for x in path if x < 1556]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Idea: for each page visited, find the weights of the keywords\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188, 3, 1, 13, 14]\n"
     ]
    }
   ],
   "source": [
    "path = path[:5]\n",
    "print(path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "outputs": [
    {
     "data": {
      "text/plain": "        weights\n8038   0.428533\n12435  0.397229\n3534   0.370644\n934    0.307061\n9451   0.232995\n13718  0.224732\n8983   0.200823\n5301   0.189491\n11227  0.187600\n...         ...\n5701   0.000000\n5702   0.000000\n5703   0.000000\n5704   0.000000\n5705   0.000000\n5706   0.000000\n5707   0.000000\n5708   0.000000\n17074  0.000000\n\n[17075 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>weights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8038</th>\n      <td>0.428533</td>\n    </tr>\n    <tr>\n      <th>12435</th>\n      <td>0.397229</td>\n    </tr>\n    <tr>\n      <th>3534</th>\n      <td>0.370644</td>\n    </tr>\n    <tr>\n      <th>934</th>\n      <td>0.307061</td>\n    </tr>\n    <tr>\n      <th>9451</th>\n      <td>0.232995</td>\n    </tr>\n    <tr>\n      <th>13718</th>\n      <td>0.224732</td>\n    </tr>\n    <tr>\n      <th>8983</th>\n      <td>0.200823</td>\n    </tr>\n    <tr>\n      <th>5301</th>\n      <td>0.189491</td>\n    </tr>\n    <tr>\n      <th>11227</th>\n      <td>0.187600</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5701</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5702</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5703</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5704</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5705</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5706</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5707</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5708</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>17074</th>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>17075 rows Ã— 1 columns</p>\n</div>"
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "weights = np.zeros(tfidf.get_number_of_keywords())\n",
    "pd.options.display.max_rows = 0\n",
    "for id in path:\n",
    "    weights += tfidf.get_all_keywords_by_id_normalized(id)\n",
    "\n",
    "df = DataFrame(weights, columns=['weights'])\n",
    "df.sort_values(by=['weights'], ascending=False)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "outputs": [
    {
     "data": {
      "text/plain": "[188, 3, 1, 13, 14, 21, 16, 14, 18, 14, 5]"
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
