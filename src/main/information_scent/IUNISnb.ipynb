{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProximalCues:\n",
    "    def __init__(self):\n",
    "        generic = lambda x: literal_eval(x)\n",
    "\n",
    "        conv = {'pc': generic}\n",
    "\n",
    "        self.urls = pd.read_csv(\"data/urls/url_references_reduced.csv\", converters=conv)\n",
    "\n",
    "    # Get the proximal cues by page id\n",
    "    def get_proximal_cues_by_id(self, id):\n",
    "        return self.urls.loc[self.urls.id==id].pc.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class TfIdf:\n",
    "    def __init__(self):\n",
    "        # Loading in the tf-idf\n",
    "        # Rows are documents, the first column is the document id\n",
    "        # Columns are keywords, the first row is the keyword id\n",
    "        self.tfidf = pd.read_csv(\"data/tf_idf/tf_idf.csv\")\n",
    "\n",
    "        # Loading in the keywords\n",
    "        # Two columns, column 1 is id, column 2 is keyword\n",
    "        # We can access the weight in the tf-idf by first accessing the id number from the keyword file\n",
    "        self.tfidf_keywords = pd.read_csv(\"data/tf_idf/tf_idf_keywords.csv\")\n",
    "        self.tfidf_keywords.columns = [\"id\", \"keyword\"]\n",
    "\n",
    "    def get_id_by_keyword(self, keyword):\n",
    "        return self.tfidf_keywords.id.iloc[self.tfidf_keywords[self.tfidf_keywords.keyword == keyword].index].values[0]\n",
    "\n",
    "\n",
    "    def get_keyword_by_id(self, id):\n",
    "        return self.tfidf_keywords.loc[self.tfidf_keywords.id==id, 'keyword'].iloc[0]\n",
    "    # Method to get the tfidf value of a keyword in a page\n",
    "    def get_tf_idf_value(self, page_id, keyword):\n",
    "        keyword_id = self.get_id_by_keyword(keyword)\n",
    "        return self.tfidf.iloc[page_id, keyword_id + 1]\n",
    "\n",
    "    def get_all_keywords_by_id(self, page_id):\n",
    "        keywords = self.tfidf.iloc[page_id][1:].values\n",
    "        return keywords\n",
    "\n",
    "    def get_all_keywords_by_id_normalized(self, page_id):\n",
    "        keywords_weights = self.get_all_keywords_by_id(page_id)\n",
    "        sum_value = sum(keywords_weights)\n",
    "        keywords_weights_normalized = keywords_weights/sum_value\n",
    "        return keywords_weights_normalized\n",
    "\n",
    "    def get_number_of_keywords(self):\n",
    "        return self.tfidf_keywords.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdjacencyMatrix:\n",
    "    def __init__(self):\n",
    "        # Loading in the adjacency matrix\n",
    "        # First column and row are data immediately, so access directly by page id\n",
    "        # If row(page_id_1) leads to column(page_id_2) = 1 else = 0\n",
    "        self.adjacency_matrix = pd.read_csv(\"data/matrices/adjacency_matrix.csv\", header=None)\n",
    "\n",
    "    # Method to get the adjacency value from two page ids\n",
    "    def get_adjacency_value(self, page_id_1, page_id_2):\n",
    "        return self.adjacency_matrix.iloc[page_id_1, page_id_2] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_matrix = AdjacencyMatrix()\n",
    "proximal_cues = ProximalCues()\n",
    "tfidf = TfIdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "generic = lambda x: literal_eval(x)\n",
    "\n",
    "conv = {'url_id_path': generic,\n",
    "        'seconds_spent_path': generic}\n",
    "df = pd.read_csv('data/clickdata/dataNoUnscrapedVisitsOrUnder20Sec.csv', converters=conv)\n",
    "\n",
    "paths = df.url_id_path\n",
    "seconds = df.seconds_spent_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [188, 1557, 3, 1, 13, 14, 21, 16, 14, 18, 14, ...\n",
       "1                               [1557, 3, 1, 13, 1556]\n",
       "2                                      [188, 194, 784]\n",
       "3                                    [23, 1557, 3, 13]\n",
       "4        [1557, 3, 1, 13, 1, 1559, 12, 1559, 17, 1556]\n",
       "5                                      [186, 217, 186]\n",
       "6                                                [188]\n",
       "7                                [1557, 3, 13, 23, 13]\n",
       "8                             [23, 1557, 23, 1557, 13]\n",
       "9                                [1557, 1, 1556, 1557]\n",
       "Name: url_id_path, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [4, 17, 5, 7, 31, 27, 126, 55, 9, 13, 3, 328, 5]\n",
       "1                                   [14, 4, 4, 33, 0]\n",
       "2                                          [5, 20, 0]\n",
       "3                                    [0, 163, 4, 151]\n",
       "4            [12, 14, 34, 66, 358, 9, 18, 19, 908, 0]\n",
       "5                                        [14, 868, 0]\n",
       "6                                                [40]\n",
       "7                                  [71, 7, 751, 1, 9]\n",
       "8                                  [1, 298, 1, 35, 6]\n",
       "9                                    [27, 15, 12, 74]\n",
       "Name: seconds_spent_path, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seconds.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took the liberty to implement my own - perhaps but not necessarily slightly simplified - version of IUNIS.\n",
    "\n",
    "Input is the ordered list of page id's that the user has visited.\n",
    "For each page, take the TF-IDF values from that page, which is a row of keywords, with either 0 if the keyword is not present or 0<value<=1 if it is.\n",
    "\n",
    "Then, for each next page, we add the TF-IDF values onto the existing weights.\n",
    "\n",
    "Eventually we can sort the list and we will have the keywords with the highest weight on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "def find_keyword_weights(path, sorted):\n",
    "    weights = np.zeros(tfidf.get_number_of_keywords())\n",
    "    pd.options.display.max_rows = 0\n",
    "    for id in path:\n",
    "        weights += tfidf.get_all_keywords_by_id_normalized(id)\n",
    "        weights /= max(weights)\n",
    "    if sorted:\n",
    "        df = DataFrame(weights, columns=['weights'])\n",
    "        return df.sort_values(by=['weights'], ascending=False)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, I introduced a factor of decay. Essentially, every iteration, all values are divided by 1.25, meaning that recent keywords are more biased.\n",
    "This is a very simple implementation, we can experiment with changing this 1.25, and also look at different implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keyword_weights_more_weight_on_recent_pages(path, decay_factor, sorted):\n",
    "    weights = np.zeros(tfidf.get_number_of_keywords())\n",
    "    pd.options.display.max_rows = 0\n",
    "    for id in path:\n",
    "        weights = weights/decay_factor\n",
    "        weights += tfidf.get_all_keywords_by_id_normalized(id)\n",
    "        weights /= max(weights)\n",
    "    if sorted:\n",
    "        df = DataFrame(weights, columns=['weights'])\n",
    "        return df.sort_values(by=['weights'], ascending=False)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keyword_weights_more_weight_on_recent_pages_and_long_time(path, secs, decay_factor, sorted):\n",
    "    weights = np.zeros(tfidf.get_number_of_keywords())\n",
    "    pd.options.display.max_rows = 0\n",
    "    for i in range(len(path)):\n",
    "        weights = weights/decay_factor\n",
    "        timeweight = secs[i]/sum(secs)\n",
    "        print(\"Timeweight:\", timeweight)\n",
    "        weights += (tfidf.get_all_keywords_by_id_normalized(path[i])*timeweight)\n",
    "        weights /= max(weights)\n",
    "    if sorted:\n",
    "        df = DataFrame(weights, columns=['weights'])\n",
    "        return df.sort_values(by=['weights'], ascending=False)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a method to print out the top 'num_of_words' weighted keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_weights_as_words(num_of_words, weights):\n",
    "    top_weights = weights.head(num_of_words)\n",
    "    i=0\n",
    "    for index in top_weights.index:\n",
    "        print(str(tfidf.get_keyword_by_id(index)) + \" : \" + str(top_weights.weights.iloc[i]))\n",
    "        i+=1\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line 2 in this section gets rid of all useless pages (login, logout, search, and error)\n",
    "Then, if the user has visited more than 5 pages, it will compute the keywords up until page 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_keywordless_pages(path, seconds):\n",
    "    indices_to_remove = []\n",
    "    for i in range(len(path)):\n",
    "        if path[i]>1555:\n",
    "            indices_to_remove.append(i)\n",
    "    for i in range(len(indices_to_remove)-1, -1, -1):\n",
    "        index = indices_to_remove[i]\n",
    "        path.pop(index)\n",
    "        seconds.pop(index)\n",
    "    return path, seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These sections computes the weights after each different page to see how it changes throughout the visit\n",
    "We can do interesting experiments to see how information need changes throughout the visit, and to find out at which page index we can best make our prediction final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188, 3, 1, 13, 14, 21, 16, 14, 18, 14, 5]\n",
      "[4, 5, 7, 31, 27, 126, 55, 9, 13, 3, 328]\n",
      "[188, 3, 1, 13, 14, 21, 16, 14, 18, 14, 5]\n",
      "[4, 5, 7, 31, 27, 126, 55, 9, 13, 3, 328]\n"
     ]
    }
   ],
   "source": [
    "print(paths[0])\n",
    "print(seconds[0])\n",
    "path, secs = remove_keywordless_pages(paths[0], seconds[0])\n",
    "print(path)\n",
    "print(secs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bijverdienen : 1.0\n",
      "gekregen : 0.875277017645266\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516527\n",
      "dekkingsgraad : 0.4982173030124242\n",
      "speciaal : 0.4324878278328123\n",
      "uitbetaling : 0.43123633353548013\n",
      "betaaldatums : 0.3672792338716384\n",
      "\n",
      "\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516527\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "speciaal : 0.4324878278328123\n",
      "uitbetaling : 0.4312363335354801\n",
      "betaaldatums : 0.36727923387163836\n",
      "\n",
      "\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516527\n",
      "laxxxxxxxxx : 0.535666062567965\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "dhr : 0.46330517813879507\n",
      "speciaal : 0.4324878278328123\n",
      "\n",
      "\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516527\n",
      "laxxxxxxxxx : 0.535666062567965\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "dhr : 0.46330517813879507\n",
      "speciaal : 0.4324878278328123\n",
      "\n",
      "\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516527\n",
      "laxxxxxxxxx : 0.535666062567965\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "samenstellen : 0.4965365250401593\n",
      "dhr : 0.46330517813879507\n",
      "\n",
      "\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516527\n",
      "laxxxxxxxxx : 0.535666062567965\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "samenstellen : 0.4965365250401593\n",
      "dhr : 0.46330517813879507\n",
      "\n",
      "\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516527\n",
      "laxxxxxxxxx : 0.535666062567965\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "dhr : 0.49721418021400965\n",
      "samenstellen : 0.4965365250401593\n",
      "\n",
      "\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "samenstellen : 0.6804729147039901\n",
      "aow : 0.5757388978926541\n",
      "buitenland : 0.5409923820516527\n",
      "laxxxxxxxxx : 0.535666062567965\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "\n",
      "\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "samenstellen : 0.6804729147039901\n",
      "aanvragen : 0.5899870236141156\n",
      "aow : 0.575738897892654\n",
      "buitenland : 0.5409923820516527\n",
      "laxxxxxxxxx : 0.535666062567965\n",
      "\n",
      "\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "samenstellen : 0.8644093043678208\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "aow : 0.767651863856872\n",
      "aanvragen : 0.681736436504515\n",
      "netto : 0.5824870512268294\n",
      "tegelijk : 0.5618295156125286\n",
      "\n",
      "\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "samenstellen : 0.8644093043678208\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "aow : 0.767651863856872\n",
      "aanvragen : 0.681736436504515\n",
      "netto : 0.5824870512268294\n",
      "tegelijk : 0.5618295156125286\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(path)):\n",
    "    subpath = path[:i+1]\n",
    "    weights = find_keyword_weights_more_weight_on_recent_pages(subpath, 1.25, True)\n",
    "    print_top_weights_as_words(10, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeweight: 1.0\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.875277017645266\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516527\n",
      "dekkingsgraad : 0.4982173030124242\n",
      "speciaal : 0.4324878278328123\n",
      "uitbetaling : 0.43123633353548013\n",
      "betaaldatums : 0.3672792338716384\n",
      "\n",
      "\n",
      "Timeweight: 0.4444444444444444\n",
      "Timeweight: 0.5555555555555556\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.820590641882869\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516527\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "speciaal : 0.4324878278328122\n",
      "uitbetaling : 0.4312363335354801\n",
      "betaaldatums : 0.36727923387163836\n",
      "\n",
      "\n",
      "Timeweight: 0.25\n",
      "Timeweight: 0.3125\n",
      "Timeweight: 0.4375\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516527\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "speciaal : 0.4324878278328123\n",
      "uitbetaling : 0.43123633353548\n",
      "betaaldatums : 0.36727923387163836\n",
      "\n",
      "\n",
      "Timeweight: 0.0851063829787234\n",
      "Timeweight: 0.10638297872340426\n",
      "Timeweight: 0.14893617021276595\n",
      "Timeweight: 0.6595744680851063\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516528\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "speciaal : 0.4324878278328123\n",
      "uitbetaling : 0.43123633353548\n",
      "betaaldatums : 0.36727923387163836\n",
      "\n",
      "\n",
      "Timeweight: 0.05405405405405406\n",
      "Timeweight: 0.06756756756756757\n",
      "Timeweight: 0.0945945945945946\n",
      "Timeweight: 0.4189189189189189\n",
      "Timeweight: 0.36486486486486486\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774323\n",
      "betaalspecificatie : 0.820590641882869\n",
      "nabetaling : 0.7961984147428293\n",
      "buitenland : 0.5409923820516527\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "speciaal : 0.43248782783281214\n",
      "uitbetaling : 0.43123633353548\n",
      "betaaldatums : 0.36727923387163836\n",
      "\n",
      "\n",
      "Timeweight: 0.02\n",
      "Timeweight: 0.025\n",
      "Timeweight: 0.035\n",
      "Timeweight: 0.155\n",
      "Timeweight: 0.135\n",
      "Timeweight: 0.63\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.820590641882869\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516527\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "speciaal : 0.43248782783281214\n",
      "uitbetaling : 0.43123633353548\n",
      "betaaldatums : 0.36727923387163836\n",
      "\n",
      "\n",
      "Timeweight: 0.01568627450980392\n",
      "Timeweight: 0.0196078431372549\n",
      "Timeweight: 0.027450980392156862\n",
      "Timeweight: 0.12156862745098039\n",
      "Timeweight: 0.10588235294117647\n",
      "Timeweight: 0.49411764705882355\n",
      "Timeweight: 0.21568627450980393\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428293\n",
      "buitenland : 0.5409923820516527\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "speciaal : 0.4324878278328123\n",
      "uitbetaling : 0.43123633353548\n",
      "betaaldatums : 0.36727923387163836\n",
      "\n",
      "\n",
      "Timeweight: 0.015151515151515152\n",
      "Timeweight: 0.01893939393939394\n",
      "Timeweight: 0.026515151515151516\n",
      "Timeweight: 0.11742424242424243\n",
      "Timeweight: 0.10227272727272728\n",
      "Timeweight: 0.4772727272727273\n",
      "Timeweight: 0.20833333333333334\n",
      "Timeweight: 0.03409090909090909\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.820590641882869\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516528\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "speciaal : 0.4324878278328123\n",
      "uitbetaling : 0.4312363335354802\n",
      "betaaldatums : 0.36727923387163836\n",
      "\n",
      "\n",
      "Timeweight: 0.01444043321299639\n",
      "Timeweight: 0.018050541516245487\n",
      "Timeweight: 0.02527075812274368\n",
      "Timeweight: 0.11191335740072202\n",
      "Timeweight: 0.09747292418772563\n",
      "Timeweight: 0.4548736462093863\n",
      "Timeweight: 0.19855595667870035\n",
      "Timeweight: 0.032490974729241874\n",
      "Timeweight: 0.04693140794223827\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.8205906418828691\n",
      "nabetaling : 0.7961984147428294\n",
      "buitenland : 0.5409923820516528\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "speciaal : 0.43248782783281214\n",
      "uitbetaling : 0.43123633353548\n",
      "betaaldatums : 0.36727923387163836\n",
      "\n",
      "\n",
      "Timeweight: 0.014285714285714285\n",
      "Timeweight: 0.017857142857142856\n",
      "Timeweight: 0.025\n",
      "Timeweight: 0.11071428571428571\n",
      "Timeweight: 0.09642857142857143\n",
      "Timeweight: 0.45\n",
      "Timeweight: 0.19642857142857142\n",
      "Timeweight: 0.03214285714285714\n",
      "Timeweight: 0.04642857142857143\n",
      "Timeweight: 0.010714285714285714\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774324\n",
      "betaalspecificatie : 0.820590641882869\n",
      "nabetaling : 0.7961984147428293\n",
      "buitenland : 0.5409923820516527\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "speciaal : 0.43248782783281214\n",
      "uitbetaling : 0.43123633353548\n",
      "betaaldatums : 0.36727923387163836\n",
      "\n",
      "\n",
      "Timeweight: 0.006578947368421052\n",
      "Timeweight: 0.008223684210526315\n",
      "Timeweight: 0.011513157894736841\n",
      "Timeweight: 0.05098684210526316\n",
      "Timeweight: 0.044407894736842105\n",
      "Timeweight: 0.20723684210526316\n",
      "Timeweight: 0.09046052631578948\n",
      "Timeweight: 0.014802631578947368\n",
      "Timeweight: 0.02138157894736842\n",
      "Timeweight: 0.004934210526315789\n",
      "Timeweight: 0.5394736842105263\n",
      "bijverdienen : 1.0\n",
      "gekregen : 0.8752770176452659\n",
      "jaaropgave : 0.8620659396774323\n",
      "betaalspecificatie : 0.820590641882869\n",
      "nabetaling : 0.7961984147428293\n",
      "buitenland : 0.5409923820516527\n",
      "dekkingsgraad : 0.4982173030124241\n",
      "speciaal : 0.43248782783281214\n",
      "uitbetaling : 0.43123633353548\n",
      "betaaldatums : 0.36727923387163836\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(path)):\n",
    "    subpath = path[:i+1]\n",
    "    subsecs = secs[:i+1]\n",
    "    weights = find_keyword_weights_more_weight_on_recent_pages_and_long_time(subpath, subsecs, 1.25, True)\n",
    "    print_top_weights_as_words(10, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea for evaluation:\n",
    "\n",
    "Look at the keywords at a specific time (we must make sure the weights are normalised, they are not in the implementation above), and compare it with a certain page near the end of the user visit to see if the user found their need.\n",
    "We can do either the last page, or maybe the page that the user has spent the most time on.\n",
    "The problem becomes that we want to evaluate the prediction of the information need, and there will be inaccuracies as the user data is not necessarily correct.\n",
    "But if we can create a metric and we can compare different implementations with the same metric we still have something nice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def estimate_most_important_page(path, seconds):\n",
    "    path = path[int(len(path)/2):]\n",
    "    seconds = seconds[int(len(seconds)/2):]\n",
    "    index = seconds.index(max(seconds))\n",
    "    return path[index]\n",
    "\n",
    "def find_keywords_of_estimated_most_important_page(path, seconds):\n",
    "    id = estimate_most_important_page(path, seconds)\n",
    "    return tfidf.get_all_keywords_by_id_normalized(id)\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "def similarity_estimated_information_need(information_need, keywords_most_important_page):\n",
    "    def cosine_similarity(list_1, list_2):\n",
    "        cos_sim = dot(list_1, list_2) / (norm(list_1) * norm(list_2))\n",
    "        return cos_sim\n",
    "    similarity = cosine_similarity(information_need, keywords_most_important_page)\n",
    "    if math.isnan(similarity):\n",
    "        return 0\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarities(subpath_size):\n",
    "    count=0\n",
    "    similarity_list = []\n",
    "    for j in range(len(paths)):\n",
    "        path, second = remove_keywordless_pages(paths[j], seconds[j])\n",
    "        if count == 1000:\n",
    "            break\n",
    "        if len(path)>6:\n",
    "            count+=1\n",
    "            subpath = path[:subpath_size]\n",
    "            weights = find_keyword_weights(subpath, False)\n",
    "            similarity_list.append(similarity_estimated_information_need(weights, find_keywords_of_estimated_most_important_page(path, second)))\n",
    "    return similarity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yv/gpc5sh7j5k3cls_fv_dpzntc0000gn/T/ipykernel_68635/484277424.py:35: RuntimeWarning: invalid value encountered in true_divide\n",
      "  keywords_weights_normalized = keywords_weights/sum_value\n"
     ]
    }
   ],
   "source": [
    "similarity_list_1 = compute_similarities(1)\n",
    "similarity_list_2 = compute_similarities(2)\n",
    "similarity_list_3 = compute_similarities(3)\n",
    "similarity_list_4 = compute_similarities(4)\n",
    "similarity_list_5 = compute_similarities(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07635014852139813\n",
      "0.09595198661187265\n",
      "0.11406294830471776\n",
      "0.13827845053808233\n",
      "0.16547565422871116\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(similarity_list_1))\n",
    "print(np.mean(similarity_list_2))\n",
    "print(np.mean(similarity_list_3))\n",
    "print(np.mean(similarity_list_4))\n",
    "print(np.mean(similarity_list_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarities_decay(decay_factor):\n",
    "    count=0\n",
    "    similarity_list = []\n",
    "    for j in range(len(paths)):\n",
    "        path, second = remove_keywordless_pages(paths[j], seconds[j])\n",
    "        if count == 1000:\n",
    "            break\n",
    "        if len(path)>6:\n",
    "            count+=1\n",
    "            subpath = path[:3]\n",
    "            weights = find_keyword_weights_more_weight_on_recent_pages(subpath, decay_factor, False)\n",
    "            similarity_list.append(similarity_estimated_information_need(weights, find_keywords_of_estimated_most_important_page(path, second)))\n",
    "    return similarity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yv/gpc5sh7j5k3cls_fv_dpzntc0000gn/T/ipykernel_68635/484277424.py:35: RuntimeWarning: invalid value encountered in true_divide\n",
      "  keywords_weights_normalized = keywords_weights/sum_value\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m avg_sim_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m51\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     similarity_list \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_similarities_decay\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     avg_sim_list\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(similarity_list))\n",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36mcompute_similarities_decay\u001b[0;34m(decay_factor)\u001b[0m\n\u001b[1;32m      9\u001b[0m         count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     10\u001b[0m         subpath \u001b[38;5;241m=\u001b[39m path[:\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m---> 11\u001b[0m         weights \u001b[38;5;241m=\u001b[39m \u001b[43mfind_keyword_weights_more_weight_on_recent_pages\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m         similarity_list\u001b[38;5;241m.\u001b[39mappend(similarity_estimated_information_need(weights, find_keywords_of_estimated_most_important_page(path, second)))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m similarity_list\n",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36mfind_keyword_weights_more_weight_on_recent_pages\u001b[0;34m(path, decay_factor, sorted)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m path:\n\u001b[1;32m      5\u001b[0m     weights \u001b[38;5;241m=\u001b[39m weights\u001b[38;5;241m/\u001b[39mdecay_factor\n\u001b[0;32m----> 6\u001b[0m     weights \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtfidf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_all_keywords_by_id_normalized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     weights \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(weights)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msorted\u001b[39m:\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mTfIdf.get_all_keywords_by_id_normalized\u001b[0;34m(self, page_id)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_keywords_by_id_normalized\u001b[39m(\u001b[38;5;28mself\u001b[39m, page_id):\n\u001b[0;32m---> 33\u001b[0m     keywords_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_all_keywords_by_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     sum_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(keywords_weights)\n\u001b[1;32m     35\u001b[0m     keywords_weights_normalized \u001b[38;5;241m=\u001b[39m keywords_weights\u001b[38;5;241m/\u001b[39msum_value\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mTfIdf.get_all_keywords_by_id\u001b[0;34m(self, page_id)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_all_keywords_by_id\u001b[39m(\u001b[38;5;28mself\u001b[39m, page_id):\n\u001b[0;32m---> 29\u001b[0m     keywords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtfidf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpage_id\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m keywords\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexing.py:967\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    964\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    966\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m--> 967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexing.py:1522\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1519\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m-> 1522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ixs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:3425\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3423\u001b[0m \u001b[38;5;66;03m# irow\u001b[39;00m\n\u001b[1;32m   3424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3425\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_xs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3427\u001b[0m     \u001b[38;5;66;03m# if we are a copy, mark as such\u001b[39;00m\n\u001b[1;32m   3428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(new_values, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m new_values\u001b[38;5;241m.\u001b[39mbase \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/managers.py:1012\u001b[0m, in \u001b[0;36mBlockManager.fast_xs\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;66;03m# Such assignment may incorrectly coerce NaT to None\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# result[blk.mgr_locs] = blk._slice((slice(None), loc))\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, rl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(blk\u001b[38;5;241m.\u001b[39mmgr_locs):\n\u001b[0;32m-> 1012\u001b[0m         result[rl] \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "avg_sim_list = []\n",
    "\n",
    "for i in range(1,51):\n",
    "    similarity_list = compute_similarities_decay(i)\n",
    "    avg_sim_list.append(np.mean(similarity_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(list(range(1,51)), avg_sim_list)\n",
    "plt.xlabel(\"Factor of Decay\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_sim_list_no_decay =[]\n",
    "\n",
    "for i in range(1,8):\n",
    "    similarity_list = compute_similarities(i)\n",
    "    avg_sim_list_no_decay.append(np.mean(similarity_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(range(1,8)), avg_sim_list_no_decay)\n",
    "plt.xlabel(\"Prediction page\")\n",
    "plt.ylabel(\"Similarity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
