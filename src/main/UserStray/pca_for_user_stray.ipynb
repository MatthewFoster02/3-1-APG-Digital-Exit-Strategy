{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [],
   "source": [
    "# functions\n",
    "def add_address_of_data(given_address): # could be useful for easily allowing others to use this file\n",
    "    return \"\".join([given_address, \"/visit_meaning_vectors/visit_meanings.csv\"])\n",
    "\n",
    "# calculating Euclidean distance\n",
    "def calculate_prob_of_visit_with_sorting(given_visit, given_pca):\n",
    "    # assuming given visit is a meaning vector, with number of variables same as number of PCs\n",
    "\n",
    "    given_pca_sorted = given_pca.sort_values(by=[\"Labels\"]) # sorting given PCA list by labels\n",
    "    prev_label = 0\n",
    "    current_label = 0\n",
    "    lowest_dist_to_visit = float('inf')\n",
    "    current_labels_dist = 0\n",
    "    total_dist = 0\n",
    "    lowest_dist_to_visits_label = 0\n",
    "\n",
    "\n",
    "    for x in range(len(given_pca_sorted)):\n",
    "        current_label = given_pca_sorted.at[given_pca_sorted.index[x], \"Labels\"] # get current label\n",
    "\n",
    "        # extracting required variables of the point in PCA data\n",
    "        temp_point = given_pca_sorted.iloc[x]\n",
    "        temp_point = temp_point.tolist()\n",
    "        temp_point = temp_point[:-1]\n",
    "\n",
    "        if current_label >= 0: # to skip \"-1\" labels\n",
    "            if current_label == prev_label: current_labels_dist += np.linalg.norm(np.array(given_visit) - np.array(temp_point)) # performing the euclidean distance calculation\n",
    "            else: # have arrived to next label in the sorted PCA, so check final values\n",
    "                if current_labels_dist < lowest_dist_to_visit:\n",
    "                    lowest_dist_to_visit = current_labels_dist\n",
    "                    lowest_dist_to_visits_label = current_label\n",
    "                prev_label = current_label\n",
    "                total_dist += current_labels_dist\n",
    "                current_labels_dist = 0 # since we are going to next label, reset distance\n",
    "\n",
    "    if total_dist == 0: print(len(given_visit))\n",
    "    return 1 - (lowest_dist_to_visits_label / total_dist), lowest_dist_to_visits_label - 1\n",
    "\n",
    "# calculating Euclidean distance and assumes that \"given_pca\" is already sorted\n",
    "def calculate_prob_of_visit_without_sorting(given_visit, given_pca_sorted):\n",
    "    # assuming given visit is a meaning vector, with number of variables same as number of PCs\n",
    "\n",
    "    prev_label = 0\n",
    "    current_label = 0\n",
    "    lowest_dist_to_visit = float('inf')\n",
    "    current_labels_dist = 0\n",
    "    total_dist = 0\n",
    "    lowest_dist_to_visits_label = 0\n",
    "\n",
    "    for x in range(0, len(given_pca_sorted)):\n",
    "        current_label = given_pca_sorted.at[given_pca_sorted.index[x], \"Labels\"] # get current label\n",
    "\n",
    "        # extracting required variables of the point in PCA data\n",
    "        temp_point = given_pca_sorted.iloc[x]\n",
    "        temp_point = temp_point.tolist()\n",
    "        temp_point = temp_point[:-1]\n",
    "\n",
    "        if current_label >= 0: # to skip \"-1\" labels\n",
    "            if current_label == prev_label: current_labels_dist += np.linalg.norm(np.array(given_visit) - np.array(temp_point)) # performing the euclidean distance calculation\n",
    "            else: # have arrived to next label in the sorted PCA, so check final values\n",
    "                if current_labels_dist < lowest_dist_to_visit:\n",
    "                    lowest_dist_to_visit = current_labels_dist\n",
    "                    lowest_dist_to_visits_label = current_label\n",
    "                prev_label = current_label\n",
    "                total_dist += current_labels_dist\n",
    "                current_labels_dist = 0 # since we are going to next label, reset distance\n",
    "\n",
    "    if total_dist == 0: print(len(given_visit))\n",
    "    return 1 - (lowest_dist_to_visits_label / total_dist), lowest_dist_to_visits_label\n",
    "\n",
    "def get_avg_pca(given_pca):\n",
    "    given_pca_sorted = given_pca.sort_values(by=[\"Labels\"]) # sorting given PCA list by labels\n",
    "    list_of_avg_values = []\n",
    "    prev_label = 0\n",
    "    current_labels_dist = [0] * (len(given_pca.columns) - 1)\n",
    "    current_label_count = 0\n",
    "    for x in range(0, len(given_pca_sorted)):\n",
    "        current_label = given_pca_sorted.at[given_pca_sorted.index[x], \"Labels\"] # get current label\n",
    "\n",
    "\n",
    "        if current_label >= 0: # to skip \"-1\" labels\n",
    "            current_label_count += 1\n",
    "\n",
    "            if current_label == prev_label:\n",
    "                # extracting required variables of the point in PCA data\n",
    "                temp_point = given_pca_sorted.iloc[x]\n",
    "                temp_point = temp_point.tolist()\n",
    "                temp_point = temp_point[:-1]\n",
    "\n",
    "                current_labels_dist = [current_labels_dist[y] + temp_point[y] for y in range (len(current_labels_dist))]\n",
    "            else: # have arrived to next label in the sorted PCA, so check final values\n",
    "                prev_label = current_label\n",
    "                list_of_avg_values.append([current_labels_dist[z] / current_label_count for z in range (len(current_labels_dist))])\n",
    "                # resetting\n",
    "                current_labels_dist = [0] * (len(given_pca.columns)-1)\n",
    "                current_label_count = 0\n",
    "\n",
    "    temp_df = pd.DataFrame(list_of_avg_values, columns=[b for b in range(0, len(given_pca.columns)-1)])\n",
    "    return temp_df\n",
    "\n",
    "# calculating Euclidean distance and assumes that \"given_pca\" is already sorted and averaged\n",
    "def calculate_prob_of_visit_with_sorted_avg_pca(given_visit, given_avg_pca_sorted):\n",
    "    # assuming given visit is a meaning vector, with number of variables same as number of PCs\n",
    "\n",
    "    lowest_dist_to_visit = float('inf')\n",
    "    total_dist = 0\n",
    "    lowest_dist_to_visits_label = 0\n",
    "\n",
    "    for x in range(0, len(given_avg_pca_sorted)): # each index is a label\n",
    "        # extracting required variables of the point in PCA data\n",
    "        temp_point = given_avg_pca_sorted.iloc[x]\n",
    "        temp_point = temp_point.tolist()\n",
    "\n",
    "        current_labels_dist = np.linalg.norm(np.array(given_visit) - np.array(temp_point)) # performing the euclidean distance calculation\n",
    "\n",
    "        if current_labels_dist < lowest_dist_to_visit:\n",
    "            lowest_dist_to_visit = current_labels_dist\n",
    "            lowest_dist_to_visits_label = x\n",
    "\n",
    "        total_dist += current_labels_dist\n",
    "\n",
    "    if total_dist == 0: print(len(given_visit))\n",
    "    return 1 - (lowest_dist_to_visits_label / total_dist), lowest_dist_to_visits_label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# meaning vectors will be made of several hundreds of variables and each cluster will have a set of data points (each data point containing values of each of these variables (so a meaning vector)\n",
    "\n",
    "# main data\n",
    "my_address = \"C:/Users/dnaen/APG_data\"  # only this has to be modified\n",
    "df = pd.read_csv(add_address_of_data(my_address))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "    visit_id  cluster_label                                               path\n0   33888[1]             -1                              [3, 1, 3, 1, 13, 956]\n1  445844[2]              0                        [1, 14, 18, 14, 31, 14, 21]\n2   39476[1]              1                                [188, 187, 3, 1, 7]\n3  671874[9]             -1      [188, 1, 14, 5, 16, 12, 22, 7, 13, 1, 12, 22]\n4  381389[1]             -1  [3, 1, 12, 7, 13, 20, 1, 12, 22, 20, 1, 13, 88...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>visit_id</th>\n      <th>cluster_label</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>33888[1]</td>\n      <td>-1</td>\n      <td>[3, 1, 3, 1, 13, 956]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>445844[2]</td>\n      <td>0</td>\n      <td>[1, 14, 18, 14, 31, 14, 21]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>39476[1]</td>\n      <td>1</td>\n      <td>[188, 187, 3, 1, 7]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>671874[9]</td>\n      <td>-1</td>\n      <td>[188, 1, 14, 5, 16, 12, 22, 7, 13, 1, 12, 22]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>381389[1]</td>\n      <td>-1</td>\n      <td>[3, 1, 12, 7, 13, 20, 1, 12, 22, 20, 1, 13, 88...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will be used to get the labels\n",
    "combined_address = \"\".join([my_address, \"/cluster_paths.csv\"])\n",
    "df_with_labels = pd.read_csv(combined_address)\n",
    "\n",
    "df_with_labels.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# dividing the dataset into a feature set and corresponding labels\n",
    "features_X = df.pop(\"meaning_vectors\")\n",
    "labels_Y = df_with_labels.pop(\"cluster_label\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "features_X = features_X.to_frame(name=\"meaning_vectors\") # converting from series to df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "                      0                     1                      2   \\\n0   [-2.8568043961120506   -1.0411711915039288     1.0061674131898883   \n1  [-0.37217951978468866   -0.6032857196871719    -0.2644388258666698   \n2    [0.8520023563924629     -0.74428102453283    -0.3087686735290868   \n3   [0.13135490096017363   -0.8527024690877495   -0.32771477870747256   \n4  [-0.18643798272444848   -1.4383675231123787    -0.4327137724151131   \n5    [0.8017517267105219   -0.7876907524983324     -0.332988247874923   \n6    [0.8520023563924629     -0.74428102453283    -0.3087686735290868   \n7    [1.5249221499351044   -1.4037420917759558    -1.1786559693686518   \n8    [1.0858290488108364   -1.2705733838081774    -1.4463061727129687   \n9     [1.627093028977404    -1.324024480073738     -1.796552349819176   \n\n                     3                      4                     5   \\\n0   -1.1113399198600664     -1.655285350981589   -2.6691645604368404   \n1    -0.705210610800887    -0.5024737471499354    1.1758432209879475   \n2    0.7550820699425076    -1.1884070250271683    0.2594626318878004   \n3    0.7094480944134656     -1.225388474398729    0.2570751190759703   \n4   -0.6960175697949025    -0.8957982682654766    -1.691897993858623   \n5     0.830129793077704    -1.1531769196160255    0.3498837970615013   \n6    0.7550820699425076    -1.1884070250271683    0.2594626318878004   \n7    -0.445124266985017   -0.49810057831439153   -0.8423023980848011   \n8   -0.2581839376364062    -1.0839809963039524   -0.9847417019354109   \n9   0.13001740207887527     -0.941459070768687   -0.5552228530119238   \n\n                     6                      7                    8   \\\n0   -2.5958565738627417   -0.18000411195911875    3.400636765062071   \n1   0.20280012297482114   -0.16655423814495635   1.1064652689149002   \n2   -0.5789710086976391    -0.4396557466653106   0.2754557052112137   \n3   -0.7784168996772194    -0.5117655031068278   0.8066044909496284   \n4   -1.4967544962443398    0.27012444394155255   2.3017233636773655   \n5   -0.5916411215336989    -0.5064417526467957   0.2931870839908932   \n6   -0.5789710086976391    -0.4396557466653106   0.2754557052112137   \n7   -0.4965743094008069     0.9325504485647284   1.5277713403101256   \n8   -1.4829461836657758      1.206394662729999    1.386778089035639   \n9   -1.3417394500338924     1.1032342875930838   0.9995642579052516   \n\n                      9   ...                     90                     91  \\\n0    -2.8970298264139283  ...    -1.0407846027233125    -1.3534519248437211   \n1   -0.23527540999357893  ...   -0.07421959972106372    -0.6932625302516809   \n2    -0.3950977929958402  ...    -0.9679174543001747   -0.01240083059794632   \n3     -0.557091680900335  ...    -0.7360540829119613   -0.16181503917053372   \n4    -0.8436691699799425  ...   -0.39684089964377395    -1.8327583531723193   \n5   -0.41130586515293277  ...    -0.9471900352710835    0.03587345923199086   \n6    -0.3950977929958402  ...    -0.9679174543001747   -0.01240083059794632   \n7    0.36636111755185563  ...     0.0573146075698068     -1.787841300602305   \n8     0.8785372346622753  ...   -0.19981773414601006    -2.2441943592574685   \n9      1.251835273194916  ...   -0.06013410368831357    -2.0734854983174844   \n\n                        92                     93                     94  \\\n0      -0.7829219487934165     0.8125388988660006      -0.90483542617853   \n1       0.9635163855450681     -0.683989136256496    -1.8281014353919036   \n2       0.7944702992178544     0.2147520861282463   -0.46089311702587055   \n3       0.6513718346307573    0.10547134970807151    -0.4870473429087532   \n4   -0.0013573005007014296      0.147503005825377   -0.20184656694915065   \n5       0.8264904988214079    0.22286894292165463    -0.4840687867477915   \n6       0.7944702992178544     0.2147520861282463   -0.46089311702587055   \n7      0.40444319568063836     0.0998980113545788     0.2666563225729433   \n8      0.15735035884862433   0.020057078780908934   -0.08027090064501201   \n9       0.4632465093783834   -0.10521439312079943   0.035861234582152644   \n\n                      95                     96                     97  \\\n0    -3.1732080388866635      1.325712796877335       0.99422387889872   \n1    0.12772723762302302   -0.30314402347148883      1.156684679867159   \n2   -0.24071347605138815     0.6540681256201899     1.0477228156685898   \n3    -0.5749379154936738     0.8275773326331273     0.7831383562317353   \n4    -1.1137789443869652    -0.4976740609206737    0.30757555534146486   \n5   -0.24091678854915255       0.62657057032324     1.1048656925778593   \n6   -0.24071347605138815     0.6540681256201899     1.0477228156685898   \n7    0.26263197553893936     -1.204812690464013   -0.18300699370489423   \n8     0.5338387721314871    -0.6411247097572574   -0.07946798972984369   \n9     0.9616596651355548    -0.8581958482899991    0.03265728496207769   \n\n                     98                     99  \n0     1.094814822799679    0.2922618730065183]  \n1    0.8138702224222183    0.7501007141180425]  \n2    0.5418776481298473    0.4532574043021911]  \n3   0.33317444603119195    0.4599801233564802]  \n4    1.7229589170293227   -0.8132785194235608]  \n5    0.4838400432639818    0.4945056179621481]  \n6    0.5418776481298473    0.4532574043021911]  \n7     2.119338408425937    -1.201881756483654]  \n8    1.3821247479600585   -1.3505309405548123]  \n9    1.2022286501795751   -1.3443378096728382]  \n\n[10 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[-2.8568043961120506</td>\n      <td>-1.0411711915039288</td>\n      <td>1.0061674131898883</td>\n      <td>-1.1113399198600664</td>\n      <td>-1.655285350981589</td>\n      <td>-2.6691645604368404</td>\n      <td>-2.5958565738627417</td>\n      <td>-0.18000411195911875</td>\n      <td>3.400636765062071</td>\n      <td>-2.8970298264139283</td>\n      <td>...</td>\n      <td>-1.0407846027233125</td>\n      <td>-1.3534519248437211</td>\n      <td>-0.7829219487934165</td>\n      <td>0.8125388988660006</td>\n      <td>-0.90483542617853</td>\n      <td>-3.1732080388866635</td>\n      <td>1.325712796877335</td>\n      <td>0.99422387889872</td>\n      <td>1.094814822799679</td>\n      <td>0.2922618730065183]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[-0.37217951978468866</td>\n      <td>-0.6032857196871719</td>\n      <td>-0.2644388258666698</td>\n      <td>-0.705210610800887</td>\n      <td>-0.5024737471499354</td>\n      <td>1.1758432209879475</td>\n      <td>0.20280012297482114</td>\n      <td>-0.16655423814495635</td>\n      <td>1.1064652689149002</td>\n      <td>-0.23527540999357893</td>\n      <td>...</td>\n      <td>-0.07421959972106372</td>\n      <td>-0.6932625302516809</td>\n      <td>0.9635163855450681</td>\n      <td>-0.683989136256496</td>\n      <td>-1.8281014353919036</td>\n      <td>0.12772723762302302</td>\n      <td>-0.30314402347148883</td>\n      <td>1.156684679867159</td>\n      <td>0.8138702224222183</td>\n      <td>0.7501007141180425]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0.8520023563924629</td>\n      <td>-0.74428102453283</td>\n      <td>-0.3087686735290868</td>\n      <td>0.7550820699425076</td>\n      <td>-1.1884070250271683</td>\n      <td>0.2594626318878004</td>\n      <td>-0.5789710086976391</td>\n      <td>-0.4396557466653106</td>\n      <td>0.2754557052112137</td>\n      <td>-0.3950977929958402</td>\n      <td>...</td>\n      <td>-0.9679174543001747</td>\n      <td>-0.01240083059794632</td>\n      <td>0.7944702992178544</td>\n      <td>0.2147520861282463</td>\n      <td>-0.46089311702587055</td>\n      <td>-0.24071347605138815</td>\n      <td>0.6540681256201899</td>\n      <td>1.0477228156685898</td>\n      <td>0.5418776481298473</td>\n      <td>0.4532574043021911]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0.13135490096017363</td>\n      <td>-0.8527024690877495</td>\n      <td>-0.32771477870747256</td>\n      <td>0.7094480944134656</td>\n      <td>-1.225388474398729</td>\n      <td>0.2570751190759703</td>\n      <td>-0.7784168996772194</td>\n      <td>-0.5117655031068278</td>\n      <td>0.8066044909496284</td>\n      <td>-0.557091680900335</td>\n      <td>...</td>\n      <td>-0.7360540829119613</td>\n      <td>-0.16181503917053372</td>\n      <td>0.6513718346307573</td>\n      <td>0.10547134970807151</td>\n      <td>-0.4870473429087532</td>\n      <td>-0.5749379154936738</td>\n      <td>0.8275773326331273</td>\n      <td>0.7831383562317353</td>\n      <td>0.33317444603119195</td>\n      <td>0.4599801233564802]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[-0.18643798272444848</td>\n      <td>-1.4383675231123787</td>\n      <td>-0.4327137724151131</td>\n      <td>-0.6960175697949025</td>\n      <td>-0.8957982682654766</td>\n      <td>-1.691897993858623</td>\n      <td>-1.4967544962443398</td>\n      <td>0.27012444394155255</td>\n      <td>2.3017233636773655</td>\n      <td>-0.8436691699799425</td>\n      <td>...</td>\n      <td>-0.39684089964377395</td>\n      <td>-1.8327583531723193</td>\n      <td>-0.0013573005007014296</td>\n      <td>0.147503005825377</td>\n      <td>-0.20184656694915065</td>\n      <td>-1.1137789443869652</td>\n      <td>-0.4976740609206737</td>\n      <td>0.30757555534146486</td>\n      <td>1.7229589170293227</td>\n      <td>-0.8132785194235608]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[0.8017517267105219</td>\n      <td>-0.7876907524983324</td>\n      <td>-0.332988247874923</td>\n      <td>0.830129793077704</td>\n      <td>-1.1531769196160255</td>\n      <td>0.3498837970615013</td>\n      <td>-0.5916411215336989</td>\n      <td>-0.5064417526467957</td>\n      <td>0.2931870839908932</td>\n      <td>-0.41130586515293277</td>\n      <td>...</td>\n      <td>-0.9471900352710835</td>\n      <td>0.03587345923199086</td>\n      <td>0.8264904988214079</td>\n      <td>0.22286894292165463</td>\n      <td>-0.4840687867477915</td>\n      <td>-0.24091678854915255</td>\n      <td>0.62657057032324</td>\n      <td>1.1048656925778593</td>\n      <td>0.4838400432639818</td>\n      <td>0.4945056179621481]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[0.8520023563924629</td>\n      <td>-0.74428102453283</td>\n      <td>-0.3087686735290868</td>\n      <td>0.7550820699425076</td>\n      <td>-1.1884070250271683</td>\n      <td>0.2594626318878004</td>\n      <td>-0.5789710086976391</td>\n      <td>-0.4396557466653106</td>\n      <td>0.2754557052112137</td>\n      <td>-0.3950977929958402</td>\n      <td>...</td>\n      <td>-0.9679174543001747</td>\n      <td>-0.01240083059794632</td>\n      <td>0.7944702992178544</td>\n      <td>0.2147520861282463</td>\n      <td>-0.46089311702587055</td>\n      <td>-0.24071347605138815</td>\n      <td>0.6540681256201899</td>\n      <td>1.0477228156685898</td>\n      <td>0.5418776481298473</td>\n      <td>0.4532574043021911]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[1.5249221499351044</td>\n      <td>-1.4037420917759558</td>\n      <td>-1.1786559693686518</td>\n      <td>-0.445124266985017</td>\n      <td>-0.49810057831439153</td>\n      <td>-0.8423023980848011</td>\n      <td>-0.4965743094008069</td>\n      <td>0.9325504485647284</td>\n      <td>1.5277713403101256</td>\n      <td>0.36636111755185563</td>\n      <td>...</td>\n      <td>0.0573146075698068</td>\n      <td>-1.787841300602305</td>\n      <td>0.40444319568063836</td>\n      <td>0.0998980113545788</td>\n      <td>0.2666563225729433</td>\n      <td>0.26263197553893936</td>\n      <td>-1.204812690464013</td>\n      <td>-0.18300699370489423</td>\n      <td>2.119338408425937</td>\n      <td>-1.201881756483654]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[1.0858290488108364</td>\n      <td>-1.2705733838081774</td>\n      <td>-1.4463061727129687</td>\n      <td>-0.2581839376364062</td>\n      <td>-1.0839809963039524</td>\n      <td>-0.9847417019354109</td>\n      <td>-1.4829461836657758</td>\n      <td>1.206394662729999</td>\n      <td>1.386778089035639</td>\n      <td>0.8785372346622753</td>\n      <td>...</td>\n      <td>-0.19981773414601006</td>\n      <td>-2.2441943592574685</td>\n      <td>0.15735035884862433</td>\n      <td>0.020057078780908934</td>\n      <td>-0.08027090064501201</td>\n      <td>0.5338387721314871</td>\n      <td>-0.6411247097572574</td>\n      <td>-0.07946798972984369</td>\n      <td>1.3821247479600585</td>\n      <td>-1.3505309405548123]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[1.627093028977404</td>\n      <td>-1.324024480073738</td>\n      <td>-1.796552349819176</td>\n      <td>0.13001740207887527</td>\n      <td>-0.941459070768687</td>\n      <td>-0.5552228530119238</td>\n      <td>-1.3417394500338924</td>\n      <td>1.1032342875930838</td>\n      <td>0.9995642579052516</td>\n      <td>1.251835273194916</td>\n      <td>...</td>\n      <td>-0.06013410368831357</td>\n      <td>-2.0734854983174844</td>\n      <td>0.4632465093783834</td>\n      <td>-0.10521439312079943</td>\n      <td>0.035861234582152644</td>\n      <td>0.9616596651355548</td>\n      <td>-0.8581958482899991</td>\n      <td>0.03265728496207769</td>\n      <td>1.2022286501795751</td>\n      <td>-1.3443378096728382]</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 100 columns</p>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expanding features df, because currently there is only one column where each row contains a list of meaning values, to make it work for PCA method defined in sklearn library, it needs to be a df where each cell is only one number\n",
    "features_X_expanded = features_X.meaning_vectors.str.split(\",\",expand=True,)\n",
    "features_X_expanded.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "100"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_X_expanded.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-58-ddb9d4d8d691>:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  fixed_first_column = features_X_expanded[0].str.replace(\"[\",\"\")\n",
      "<ipython-input-58-ddb9d4d8d691>:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  fixed_last_column = features_X_expanded[99].str.replace(\"]\",\"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "                     0                     1                      2   \\\n0   -2.8568043961120506   -1.0411711915039288     1.0061674131898883   \n1  -0.37217951978468866   -0.6032857196871719    -0.2644388258666698   \n2    0.8520023563924629     -0.74428102453283    -0.3087686735290868   \n3   0.13135490096017363   -0.8527024690877495   -0.32771477870747256   \n4  -0.18643798272444848   -1.4383675231123787    -0.4327137724151131   \n\n                     3                     4                     5   \\\n0   -1.1113399198600664    -1.655285350981589   -2.6691645604368404   \n1    -0.705210610800887   -0.5024737471499354    1.1758432209879475   \n2    0.7550820699425076   -1.1884070250271683    0.2594626318878004   \n3    0.7094480944134656    -1.225388474398729    0.2570751190759703   \n4   -0.6960175697949025   -0.8957982682654766    -1.691897993858623   \n\n                     6                      7                    8   \\\n0   -2.5958565738627417   -0.18000411195911875    3.400636765062071   \n1   0.20280012297482114   -0.16655423814495635   1.1064652689149002   \n2   -0.5789710086976391    -0.4396557466653106   0.2754557052112137   \n3   -0.7784168996772194    -0.5117655031068278   0.8066044909496284   \n4   -1.4967544962443398    0.27012444394155255   2.3017233636773655   \n\n                      9   ...                     90                     91  \\\n0    -2.8970298264139283  ...    -1.0407846027233125    -1.3534519248437211   \n1   -0.23527540999357893  ...   -0.07421959972106372    -0.6932625302516809   \n2    -0.3950977929958402  ...    -0.9679174543001747   -0.01240083059794632   \n3     -0.557091680900335  ...    -0.7360540829119613   -0.16181503917053372   \n4    -0.8436691699799425  ...   -0.39684089964377395    -1.8327583531723193   \n\n                        92                    93                     94  \\\n0      -0.7829219487934165    0.8125388988660006      -0.90483542617853   \n1       0.9635163855450681    -0.683989136256496    -1.8281014353919036   \n2       0.7944702992178544    0.2147520861282463   -0.46089311702587055   \n3       0.6513718346307573   0.10547134970807151    -0.4870473429087532   \n4   -0.0013573005007014296     0.147503005825377   -0.20184656694915065   \n\n                      95                     96                    97  \\\n0    -3.1732080388866635      1.325712796877335      0.99422387889872   \n1    0.12772723762302302   -0.30314402347148883     1.156684679867159   \n2   -0.24071347605138815     0.6540681256201899    1.0477228156685898   \n3    -0.5749379154936738     0.8275773326331273    0.7831383562317353   \n4    -1.1137789443869652    -0.4976740609206737   0.30757555534146486   \n\n                     98                    99  \n0     1.094814822799679    0.2922618730065183  \n1    0.8138702224222183    0.7501007141180425  \n2    0.5418776481298473    0.4532574043021911  \n3   0.33317444603119195    0.4599801233564802  \n4    1.7229589170293227   -0.8132785194235608  \n\n[5 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-2.8568043961120506</td>\n      <td>-1.0411711915039288</td>\n      <td>1.0061674131898883</td>\n      <td>-1.1113399198600664</td>\n      <td>-1.655285350981589</td>\n      <td>-2.6691645604368404</td>\n      <td>-2.5958565738627417</td>\n      <td>-0.18000411195911875</td>\n      <td>3.400636765062071</td>\n      <td>-2.8970298264139283</td>\n      <td>...</td>\n      <td>-1.0407846027233125</td>\n      <td>-1.3534519248437211</td>\n      <td>-0.7829219487934165</td>\n      <td>0.8125388988660006</td>\n      <td>-0.90483542617853</td>\n      <td>-3.1732080388866635</td>\n      <td>1.325712796877335</td>\n      <td>0.99422387889872</td>\n      <td>1.094814822799679</td>\n      <td>0.2922618730065183</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.37217951978468866</td>\n      <td>-0.6032857196871719</td>\n      <td>-0.2644388258666698</td>\n      <td>-0.705210610800887</td>\n      <td>-0.5024737471499354</td>\n      <td>1.1758432209879475</td>\n      <td>0.20280012297482114</td>\n      <td>-0.16655423814495635</td>\n      <td>1.1064652689149002</td>\n      <td>-0.23527540999357893</td>\n      <td>...</td>\n      <td>-0.07421959972106372</td>\n      <td>-0.6932625302516809</td>\n      <td>0.9635163855450681</td>\n      <td>-0.683989136256496</td>\n      <td>-1.8281014353919036</td>\n      <td>0.12772723762302302</td>\n      <td>-0.30314402347148883</td>\n      <td>1.156684679867159</td>\n      <td>0.8138702224222183</td>\n      <td>0.7501007141180425</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.8520023563924629</td>\n      <td>-0.74428102453283</td>\n      <td>-0.3087686735290868</td>\n      <td>0.7550820699425076</td>\n      <td>-1.1884070250271683</td>\n      <td>0.2594626318878004</td>\n      <td>-0.5789710086976391</td>\n      <td>-0.4396557466653106</td>\n      <td>0.2754557052112137</td>\n      <td>-0.3950977929958402</td>\n      <td>...</td>\n      <td>-0.9679174543001747</td>\n      <td>-0.01240083059794632</td>\n      <td>0.7944702992178544</td>\n      <td>0.2147520861282463</td>\n      <td>-0.46089311702587055</td>\n      <td>-0.24071347605138815</td>\n      <td>0.6540681256201899</td>\n      <td>1.0477228156685898</td>\n      <td>0.5418776481298473</td>\n      <td>0.4532574043021911</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.13135490096017363</td>\n      <td>-0.8527024690877495</td>\n      <td>-0.32771477870747256</td>\n      <td>0.7094480944134656</td>\n      <td>-1.225388474398729</td>\n      <td>0.2570751190759703</td>\n      <td>-0.7784168996772194</td>\n      <td>-0.5117655031068278</td>\n      <td>0.8066044909496284</td>\n      <td>-0.557091680900335</td>\n      <td>...</td>\n      <td>-0.7360540829119613</td>\n      <td>-0.16181503917053372</td>\n      <td>0.6513718346307573</td>\n      <td>0.10547134970807151</td>\n      <td>-0.4870473429087532</td>\n      <td>-0.5749379154936738</td>\n      <td>0.8275773326331273</td>\n      <td>0.7831383562317353</td>\n      <td>0.33317444603119195</td>\n      <td>0.4599801233564802</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.18643798272444848</td>\n      <td>-1.4383675231123787</td>\n      <td>-0.4327137724151131</td>\n      <td>-0.6960175697949025</td>\n      <td>-0.8957982682654766</td>\n      <td>-1.691897993858623</td>\n      <td>-1.4967544962443398</td>\n      <td>0.27012444394155255</td>\n      <td>2.3017233636773655</td>\n      <td>-0.8436691699799425</td>\n      <td>...</td>\n      <td>-0.39684089964377395</td>\n      <td>-1.8327583531723193</td>\n      <td>-0.0013573005007014296</td>\n      <td>0.147503005825377</td>\n      <td>-0.20184656694915065</td>\n      <td>-1.1137789443869652</td>\n      <td>-0.4976740609206737</td>\n      <td>0.30757555534146486</td>\n      <td>1.7229589170293227</td>\n      <td>-0.8132785194235608</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 100 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since we have expanded a string of list, we also have to remove \"[\" and \"]\" from first and last column\n",
    "fixed_first_column = features_X_expanded[0].str.replace(\"[\",\"\")\n",
    "fixed_last_column = features_X_expanded[99].str.replace(\"]\",\"\")\n",
    "\n",
    "features_X_expanded[0] = fixed_first_column\n",
    "features_X_expanded[99] = fixed_last_column\n",
    "\n",
    "features_X_expanded.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "array([2.67436094e-01, 1.38522735e-01, 1.23398167e-01, 8.78706719e-02,\n       7.92398468e-02, 3.86371569e-02, 3.36798332e-02, 2.27995672e-02,\n       2.01238782e-02, 1.64326961e-02, 1.34371143e-02, 1.32297856e-02,\n       1.18166805e-02, 1.09812838e-02, 9.81884140e-03, 8.91401525e-03,\n       7.48935237e-03, 7.38501282e-03, 7.04718604e-03, 5.71110649e-03,\n       5.30549423e-03, 4.80035576e-03, 4.39012934e-03, 4.05731983e-03,\n       3.70182515e-03, 3.46913935e-03, 3.31339869e-03, 2.92080531e-03,\n       2.68417073e-03, 2.54992633e-03, 2.39285727e-03, 2.30611020e-03,\n       2.11745014e-03, 1.98971377e-03, 1.74529967e-03, 1.57725165e-03,\n       1.51758151e-03, 1.42356224e-03, 1.36693560e-03, 1.22390893e-03,\n       1.20126941e-03, 1.07048150e-03, 1.04657333e-03, 9.56930646e-04,\n       9.17216574e-04, 8.86532352e-04, 8.09206170e-04, 7.57266610e-04,\n       7.41189798e-04, 6.97078236e-04, 6.61805194e-04, 6.13954555e-04,\n       5.85811206e-04, 5.72936776e-04, 5.34902017e-04, 4.94177296e-04,\n       4.85336844e-04, 4.50376449e-04, 4.40554340e-04, 4.29886579e-04,\n       4.12961534e-04, 3.77804290e-04, 3.57325793e-04, 3.25689326e-04,\n       3.05412996e-04, 2.94351795e-04, 2.78584647e-04, 2.65611207e-04,\n       2.60569248e-04, 2.45835407e-04, 2.31528614e-04, 2.23756092e-04,\n       2.15682935e-04, 2.04108281e-04, 1.93670707e-04, 1.84538978e-04,\n       1.78387102e-04, 1.69720255e-04, 1.63648111e-04, 1.52029839e-04,\n       1.42250398e-04, 1.36726769e-04, 1.33910662e-04, 1.26838782e-04,\n       1.18272002e-04, 1.05841410e-04, 1.03204422e-04, 9.72163648e-05,\n       9.65663560e-05, 9.20915832e-05, 8.84907255e-05, 8.62307882e-05,\n       7.56344451e-05, 7.14367294e-05, 6.86163014e-05, 6.58091606e-05,\n       6.25453505e-05, 5.62671318e-05, 5.15438988e-05, 1.54302783e-06])"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform PCA on all data\n",
    "# first create train and test\n",
    "features_X_expanded[\"Labels\"] = labels_Y # appending labels to not lose their assigned labels when performing data split\n",
    "train, test = train_test_split(features_X_expanded, test_size=0.2)\n",
    "\n",
    "# saving labels\n",
    "train_labels = train.pop(\"Labels\")\n",
    "features_X_expanded = train\n",
    "\n",
    "test_labels = test.pop(\"Labels\")\n",
    "\n",
    "# Scaling features such that they all have a mean of 0 and a variance of 1\n",
    "scaler = StandardScaler()\n",
    "scaled_train = scaler.fit_transform(features_X_expanded)\n",
    "\n",
    "pca = PCA() # can be replaced with \"PCA(n_components=2)\" but need to check variance ratio first\n",
    "pca_train = pca.fit_transform(scaled_train)\n",
    "\n",
    "pca.explained_variance_ratio_ # observing how much each PCA is responsible for the variance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# pca_train_allPCs_df = pd.DataFrame(pca_train, columns = [*range(0, pca_train.shape[1])])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "# extracting all PCs data to cvs file\n",
    "# pca_train_allPCs_df.to_csv(\"C:/Users/dnaen/APG_data/pca_train_allPCs.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2) # to be able to do Euclidean distance calculation set to 2\n",
    "pca_train_2PCs = pca.fit_transform(scaled_train)\n",
    "pca_train_2PCs_df = pd.DataFrame(pca_train_2PCs, columns = ['PC1','PC2'])\n",
    "pca_train_2PCs_df[\"Labels\"] = train_labels.values # can just append it since row order is not affected"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "# setting up test\n",
    "scaled_test = scaler.transform(test)\n",
    "pca_test_2PCs = pca.transform(scaled_test)\n",
    "\n",
    "pca_test_2PCs_df = pd.DataFrame(pca_test_2PCs, columns = ['PC1','PC2'])\n",
    "pca_test_2PCs_df[\"Labels\"] = test_labels.values # can just append it since row order is not affected"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "         PC1       PC2  Labels\n0  -5.924999  0.348279      -1\n1  -2.711920  2.977129      -1\n2   1.307778 -4.317033      -1\n3  14.969915 -3.218908      13\n4   2.783498 -1.978736      -1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-5.924999</td>\n      <td>0.348279</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-2.711920</td>\n      <td>2.977129</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.307778</td>\n      <td>-4.317033</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14.969915</td>\n      <td>-3.218908</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.783498</td>\n      <td>-1.978736</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_test_2PCs_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# to extract file to csv\n",
    "# pca_data_2PCs_df.to_csv(\"C:/Users/dnaen/APG_data/pca_data_2PCs.csv\", index=False)\n",
    "\n",
    "# to extract from csv\n",
    "# pca_data_2PCs_df = pd.read_csv(\".../pca_data_2PCs.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1\n0 -4.975416 -1.530899\n1 -4.424312 -0.232859\n2  0.348942 -4.525183\n3 -1.971355 -4.359000\n4 -0.873455  2.556172",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-4.975416</td>\n      <td>-1.530899</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-4.424312</td>\n      <td>-0.232859</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.348942</td>\n      <td>-4.525183</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.971355</td>\n      <td>-4.359000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.873455</td>\n      <td>2.556172</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to use at visit prob. calculation later\n",
    "pca_train_2PCs_df_sorted = pca_train_2PCs_df.sort_values(by=[\"Labels\"])\n",
    "avg_pca_train_2PCs_df = get_avg_pca(pca_train_2PCs_df_sorted)\n",
    "avg_pca_train_2PCs_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment size:\n",
      "200\n",
      "Accurate prediction with prob.\n",
      "0.255\n",
      "False prediction with prob.\n",
      "0.235\n"
     ]
    }
   ],
   "source": [
    "# experiment 1 - done for 2 PCs going through all PCA\n",
    "accurate_estimation_prob = 0\n",
    "false_estimation_prob = 0\n",
    "\n",
    "total_accurate_prob = 0\n",
    "total_false_prob = 0\n",
    "\n",
    "# row size (number of data points)\n",
    "row_size = len(pca_test_2PCs_df.axes[0])\n",
    "experiment_size = 200\n",
    "random_list = [] # for experiment\n",
    "for y in range(0, experiment_size):\n",
    "    random_list.append(random.randint(0, row_size))\n",
    "\n",
    "# only using \"pca_test_2comp_df_sorted\" such that labels match\n",
    "for x in random_list:\n",
    "    label = pca_test_2PCs_df.at[pca_test_2PCs_df.index[x], \"Labels\"]\n",
    "    if label >= 0:\n",
    "        current_visit = pca_test_2PCs_df.iloc[x]\n",
    "        current_visit = current_visit.tolist()\n",
    "        current_visit = current_visit[:-1]\n",
    "\n",
    "        estimated_prob, estimated_label = calculate_prob_of_visit_with_sorting(current_visit, pca_train_2PCs_df_sorted)\n",
    "\n",
    "        if estimated_label == label:\n",
    "            total_accurate_prob += 1\n",
    "        else:\n",
    "            total_false_prob += 1\n",
    "\n",
    "accurate_estimation_prob = total_accurate_prob / experiment_size\n",
    "false_estimation_prob = total_false_prob / experiment_size\n",
    "\n",
    "print(\"Experiment size:\")\n",
    "print(experiment_size)\n",
    "print(\"Accurate prediction with prob.\")\n",
    "print(accurate_estimation_prob)\n",
    "print(\"False prediction with prob.\")\n",
    "print(false_estimation_prob)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Can save results here\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment size:\n",
      "19948\n",
      "Accurate prediction with prob.\n",
      "0.48280529376378584\n",
      "False prediction with prob.\n",
      "0.009274112693001805\n"
     ]
    }
   ],
   "source": [
    "# experiment 2 - done for 2 PCs with averaged PCA\n",
    "accurate_estimation_prob = 0\n",
    "false_estimation_prob = 0\n",
    "\n",
    "total_accurate_prob = 0\n",
    "total_false_prob = 0\n",
    "\n",
    "# row size (number of data points)\n",
    "row_size = len(pca_test_2PCs_df.axes[0])\n",
    "experiment_size = row_size\n",
    "random_list = [] # for experiment\n",
    "\n",
    "for x in range(experiment_size):\n",
    "    label = pca_test_2PCs_df.at[pca_test_2PCs_df.index[x], \"Labels\"]\n",
    "    if label >= 0:\n",
    "        current_visit = pca_test_2PCs_df.iloc[x]\n",
    "        current_visit = current_visit.tolist()\n",
    "        current_visit = current_visit[:-1]\n",
    "        estimated_prob, estimated_label = calculate_prob_of_visit_with_sorted_avg_pca(current_visit, avg_pca_train_2PCs_df) # visit extracted from test data, pca extracted from train data\n",
    "\n",
    "        if estimated_label == label:\n",
    "            total_accurate_prob += 1\n",
    "        else:\n",
    "            total_false_prob += 1\n",
    "\n",
    "accurate_estimation_prob = total_accurate_prob / experiment_size\n",
    "false_estimation_prob = total_false_prob / experiment_size\n",
    "\n",
    "print(\"Experiment size:\")\n",
    "print(experiment_size)\n",
    "print(\"Accurate prediction with prob.\")\n",
    "print(accurate_estimation_prob)\n",
    "print(\"False prediction with prob.\")\n",
    "print(false_estimation_prob)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- with split -\n",
    "Experiment size:\n",
    "1438474\n",
    "Accurate prediction with prob.\n",
    "0.1430056135838301\n",
    "False prediction with prob.\n",
    "0.05483585046664002\n",
    "- without split -\n",
    "Experiment size:\n",
    "1438474\n",
    "Accurate prediction with prob.\n",
    "0.6983720247985018\n",
    "False prediction with prob.\n",
    "0.2959629440643348\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
