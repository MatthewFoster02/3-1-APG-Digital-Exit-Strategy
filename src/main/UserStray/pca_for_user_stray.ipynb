{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# functions\n",
    "def add_address_of_data(given_address): # could be useful for easily allowing others to use this file\n",
    "    return \"\".join([given_address, \"/visit_meaning_vectors/visit_meanings.csv\"])\n",
    "\n",
    "# calculating Euclidean distance\n",
    "def calculate_prob_of_visit_with_sorting(given_visit, given_pca):\n",
    "    # assuming given visit is a meaning vector, with number of variables same as number of PCs\n",
    "\n",
    "    given_pca_sorted = given_pca.sort_values(by=[\"Labels\"]) # sorting given PCA list by labels\n",
    "    prev_label = 0\n",
    "    current_label = 0\n",
    "    lowest_dist_to_visit = 0\n",
    "    current_labels_dist = 0\n",
    "    total_dist = 0\n",
    "    lowest_dist_to_visits_label = 0\n",
    "\n",
    "    for x in range(0, len(given_pca_sorted)):\n",
    "        current_label = given_pca_sorted.at[given_pca_sorted.index[x], \"Labels\"] # get current label\n",
    "\n",
    "        # extracting required variables of the point in PCA data\n",
    "        temp_point = given_pca_sorted.iloc[x]\n",
    "        temp_point = temp_point.tolist()\n",
    "        temp_point = temp_point[:-1]\n",
    "\n",
    "        if current_label >= 0: # to skip \"-1\" labels\n",
    "            if current_label == prev_label: current_labels_dist += np.linalg.norm(np.array(given_visit) - np.array(temp_point)) # performing the euclidean distance calculation\n",
    "            else: # have arrived to next label in the sorted PCA, so check final values\n",
    "                if current_labels_dist < lowest_dist_to_visit:\n",
    "                    lowest_dist_to_visit = current_labels_dist\n",
    "                    lowest_dist_to_visits_label = current_label\n",
    "                prev_label = current_label\n",
    "                total_dist += current_labels_dist\n",
    "                current_labels_dist = 0 # since we are going to next label, reset distance\n",
    "\n",
    "    if total_dist == 0: print(len(given_visit))\n",
    "    return 1 - (lowest_dist_to_visits_label / total_dist), lowest_dist_to_visits_label\n",
    "\n",
    "# calculating Euclidean distance and assumes that \"given_pca\" is already sorted\n",
    "def calculate_prob_of_visit_without_sorting(given_visit, given_pca_sorted):\n",
    "    # assuming given visit is a meaning vector, with number of variables same as number of PCs\n",
    "\n",
    "    prev_label = 0\n",
    "    current_label = 0\n",
    "    lowest_dist_to_visit = 0\n",
    "    current_labels_dist = 0\n",
    "    total_dist = 0\n",
    "    lowest_dist_to_visits_label = 0\n",
    "\n",
    "    for x in range(0, len(given_pca_sorted)):\n",
    "        current_label = given_pca_sorted.at[given_pca_sorted.index[x], \"Labels\"] # get current label\n",
    "\n",
    "        # extracting required variables of the point in PCA data\n",
    "        temp_point = given_pca_sorted.iloc[x]\n",
    "        temp_point = temp_point.tolist()\n",
    "        temp_point = temp_point[:-1]\n",
    "\n",
    "        if current_label >= 0: # to skip \"-1\" labels\n",
    "            if current_label == prev_label: current_labels_dist += np.linalg.norm(np.array(given_visit) - np.array(temp_point)) # performing the euclidean distance calculation\n",
    "            else: # have arrived to next label in the sorted PCA, so check final values\n",
    "                if current_labels_dist < lowest_dist_to_visit:\n",
    "                    lowest_dist_to_visit = current_labels_dist\n",
    "                    lowest_dist_to_visits_label = current_label\n",
    "                prev_label = current_label\n",
    "                total_dist += current_labels_dist\n",
    "                current_labels_dist = 0 # since we are going to next label, reset distance\n",
    "\n",
    "    if total_dist == 0: print(len(given_visit))\n",
    "    return 1 - (lowest_dist_to_visits_label / total_dist), lowest_dist_to_visits_label\n",
    "\n",
    "def get_avg_pca(given_pca):\n",
    "    given_pca_sorted = given_pca.sort_values(by=[\"Labels\"]) # sorting given PCA list by labels\n",
    "    list_of_avg_values = []\n",
    "    prev_label = 0\n",
    "    current_labels_dist = [0] * (len(given_pca.columns) - 1)\n",
    "    current_label_count = 0\n",
    "    for x in range(0, len(given_pca_sorted)):\n",
    "        current_label = given_pca_sorted.at[given_pca_sorted.index[x], \"Labels\"] # get current label\n",
    "\n",
    "\n",
    "        if current_label >= 0: # to skip \"-1\" labels\n",
    "            current_label_count += 1\n",
    "\n",
    "            if current_label == prev_label:\n",
    "                # extracting required variables of the point in PCA data\n",
    "                temp_point = given_pca_sorted.iloc[x]\n",
    "                temp_point = temp_point.tolist()\n",
    "                temp_point = temp_point[:-1]\n",
    "\n",
    "                current_labels_dist = [current_labels_dist[y] + temp_point[y] for y in range (0, len(current_labels_dist))]\n",
    "            else: # have arrived to next label in the sorted PCA, so check final values\n",
    "                prev_label = current_label\n",
    "                list_of_avg_values.append([current_labels_dist[z] / current_label_count for z in range (0, len(current_labels_dist))])\n",
    "                # resetting\n",
    "                current_labels_dist = [0] * (len(given_pca.columns)-1)\n",
    "                current_label_count = 0\n",
    "\n",
    "    temp_df = pd.DataFrame(list_of_avg_values, columns=[b for b in range(0, len(given_pca.columns)-1)])\n",
    "    return temp_df\n",
    "\n",
    "# calculating Euclidean distance and assumes that \"given_pca\" is already sorted and averaged\n",
    "def calculate_prob_of_visit_with_sorted_avg_pca(given_visit, given_avg_pca_sorted):\n",
    "    # assuming given visit is a meaning vector, with number of variables same as number of PCs\n",
    "\n",
    "    lowest_dist_to_visit = 0\n",
    "    current_labels_dist = 0\n",
    "    total_dist = 0\n",
    "    lowest_dist_to_visits_label = 0\n",
    "\n",
    "    for x in range(0, len(given_avg_pca_sorted)): # each index is a label\n",
    "        # extracting required variables of the point in PCA data\n",
    "        temp_point = given_avg_pca_sorted.iloc[x]\n",
    "        temp_point = temp_point.tolist()\n",
    "        temp_point = temp_point[:-1]\n",
    "\n",
    "        current_labels_dist += np.linalg.norm(np.array(given_visit) - np.array(temp_point)) # performing the euclidean distance calculation\n",
    "\n",
    "        if current_labels_dist < lowest_dist_to_visit:\n",
    "            lowest_dist_to_visit = current_labels_dist\n",
    "            lowest_dist_to_visits_label = x\n",
    "\n",
    "        total_dist += current_labels_dist\n",
    "        current_labels_dist = 0 # since we are going to next label, reset distance\n",
    "\n",
    "    if total_dist == 0: print(len(given_visit))\n",
    "    return 1 - (lowest_dist_to_visits_label / total_dist), lowest_dist_to_visits_label"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# meaning vectors will be made of several hundreds of variables and each cluster will have a set of data points (each data point containing values of each of these variables (so a meaning vector)\n",
    "\n",
    "# main data\n",
    "my_address = \"C:/Users/dnaen/APG_data\"  # only this has to be modified\n",
    "df = pd.read_csv(add_address_of_data(my_address))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "  visit_id  cluster_label                                               path\n0     0[1]              0  [188, 1557, 3, 1, 13, 14, 21, 16, 14, 18, 14, ...\n1     5[1]              0      [1557, 3, 1, 13, 1, 1559, 12, 1559, 17, 1556]\n2     9[1]              0  [1557, 3, 86, 3, 86, 3, 92, 3, 7, 19, 14, 18, ...\n3    11[1]              0  [188, 228, 1557, 3, 1, 12, 7, 20, 1, 7, 1, 12,...\n4    12[4]             18                          [1557, 1, 17, 12, 17, 13]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>visit_id</th>\n      <th>cluster_label</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0[1]</td>\n      <td>0</td>\n      <td>[188, 1557, 3, 1, 13, 14, 21, 16, 14, 18, 14, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5[1]</td>\n      <td>0</td>\n      <td>[1557, 3, 1, 13, 1, 1559, 12, 1559, 17, 1556]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9[1]</td>\n      <td>0</td>\n      <td>[1557, 3, 86, 3, 86, 3, 92, 3, 7, 19, 14, 18, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11[1]</td>\n      <td>0</td>\n      <td>[188, 228, 1557, 3, 1, 12, 7, 20, 1, 7, 1, 12,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12[4]</td>\n      <td>18</td>\n      <td>[1557, 1, 17, 12, 17, 13]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# will be used to get the labels\n",
    "combined_address = \"\".join([my_address, \"/cluster_paths.csv\"])\n",
    "df_with_labels = pd.read_csv(combined_address)\n",
    "\n",
    "df_with_labels.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# dividing the dataset into a feature set and corresponding labels\n",
    "features_X = df.pop(\"meaning_vectors\")\n",
    "labels_Y = df_with_labels.pop(\"cluster_label\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "features_X = features_X.to_frame(name=\"meaning_vectors\") # converting from series to df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                      0                     1                      2   \\\n0   [-1.0013970414243027   0.10410662986918126    -0.7069594929319728   \n1  [-0.22001658113151915   -2.2507345794274003   -0.39334745766392143   \n2     [1.597802667104453   -1.3318458039597452    -1.7876896274176677   \n3  [-0.08318374597228116   -0.8729878666888199    0.04103715385277553   \n4    [-2.879218311253632   -1.2799126645257008     1.4575141945832106   \n5   [-0.8369180614741538   -0.9360479342720077    -1.4600495143301906   \n6   [0.41522979898676204    -1.159737958953214   -0.24958176524187306   \n7   [-2.9608902166864195   -1.0956738286472025     1.5058700002833443   \n8  [-0.21947748986132684   -2.2178541207713884   -0.41563905313300975   \n9     [1.636401249004699   -1.3215432693000375     -1.799365303324645   \n\n                      3                        4                      5   \\\n0   -0.36709259026598773      -2.1300366871439413     0.5969171592180543   \n1   -0.22047120988704638      -0.7654681601639308     -1.142924618070034   \n2     0.1531999657748357      -0.9184955153229891    -0.5461559025055277   \n3     0.4616454791874244      -1.2901850509770025   -0.32690479632566644   \n4     -1.166744513134016      -1.3042470403141233    -2.9598892548443834   \n5     0.6728528936018906      -2.0424073705869854     0.8780426693652943   \n6   -0.13623317566661258   -0.0028182256505899146     -0.113359035790069   \n7    -1.4171404701882868       -1.330844679769079    -3.2280216641241934   \n8   -0.22944012568942837      -0.7795311621539934    -1.1547154513449471   \n9    0.12268648799344105      -0.9487439002267276    -0.5580854809242989   \n\n                      6                      7                    8   \\\n0   -0.03271988515836363    0.22249206804431765   2.0278810990021037   \n1      -1.86187248369162    -2.3556492318840334   0.4819600693957551   \n2    -1.3570081626634485     1.0627681533667157   0.9851826480709566   \n3    -1.1119495148239313    -0.4324641976679138   1.0586961520473588   \n4     -3.275919495479953    -0.8904921384608795    3.356320868826463   \n5     0.6503694747009278    -0.7550821150290333    0.987214469378856   \n6    -1.5764256339857223     -2.286969566939029   0.7884043577574544   \n7     -2.914351798926398   -0.15371908870942233      3.7869134416421   \n8    -1.8051821470791596    -2.2811334928079656   0.5249316969983312   \n9     -1.336901155508226      1.116053957525558   1.0041238951464682   \n\n                     9   ...                     90                     91  \\\n0     0.827870212403462  ...     0.6548517055350448   -0.38468799598436426   \n1   0.18859658647643737  ...    -2.9357195712888546    -1.4991282068852751   \n2    1.2266712267690123  ...   -0.08874881949668298     -2.042117278138647   \n3   -1.0272654039747169  ...    -1.0450595649908427   -0.21682913857705483   \n4     -2.58905896196911  ...    -1.6676139719707401     -1.561016979377544   \n5   -1.8657573549489026  ...    -0.7416060416975647   -0.03952623912108067   \n6   -0.8258271395134206  ...     0.9086259165978999    -0.9989015212295889   \n7   -3.0848926771574683  ...    -1.0075266551915474     -1.431580054894582   \n8   0.20879004035050058  ...     -2.856059562474998    -1.5353509528367395   \n9    1.2598132746366242  ...   -0.05103576905599793     -2.083416129378853   \n\n                     92                     93                     94  \\\n0    1.1044825047930154     0.3155223956828208    -2.8847950848931903   \n1    1.0062288988970693    -0.8182551957518548   -0.03623077012179573   \n2   0.44127326653992904   -0.11127071569812472   0.013890977112452017   \n3    0.5135529541165453    0.24952462880443266    -0.4754690515821106   \n4   -0.6728326083361991     0.4044155336332753    -0.7633771138154553   \n5    0.7452824610817166     1.3450202088510912    -1.0320636113872825   \n6   -0.6314352109646598     -2.632272249209213     -1.091078694284572   \n7   -0.9603913965546478     0.6739031904247236    -0.7635178779790973   \n8    0.9520496397599718    -0.7985087925155984   -0.04356704773773685   \n9    0.4702529315839726   -0.10329644329994535    0.04284644537085021   \n\n                      95                     96                     97  \\\n0    -0.7553962498890037    -1.4720945990902772      2.653286573843067   \n1    -1.7267140207545708    0.42753339462984424    -0.2442145154380059   \n2       0.95533802751127    -0.8402656332947769   0.061700693517540386   \n3    -0.8941292800735631     0.7727549164157642     1.0482704489062364   \n4    -3.7231811983314644     1.7113150440592182     0.6782706184706131   \n5   -0.36690024502287766    -0.3993312144790031      1.434885437273656   \n6   -0.06114190398377731   0.013034119396266025    0.23678484198785382   \n7     -3.653489183589961     1.4316337850813414     0.8270008493919788   \n8    -1.7113681682832265     0.4324085498406598    -0.2619146641405508   \n9     0.9636512408517387    -0.8638822929503234    0.02346379734516011   \n\n                     98                      99  \n0   0.19436177212666456     0.1434588478106824]  \n1     1.433941992453667    -1.8641315484083514]  \n2     1.174434637245242    -1.3317815829510649]  \n3    0.7197991172110915    0.45537440922683853]  \n4    1.3848466663654022    -0.3254715591507867]  \n5   0.22887428557260156     1.6715811412887076]  \n6    1.3449782613104728     -0.538909557924523]  \n7     1.434033033769334   0.030364470567248808]  \n8    1.4221927650774926     -1.854721102828428]  \n9     1.211031653527771     -1.348301502039101]  \n\n[10 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[-1.0013970414243027</td>\n      <td>0.10410662986918126</td>\n      <td>-0.7069594929319728</td>\n      <td>-0.36709259026598773</td>\n      <td>-2.1300366871439413</td>\n      <td>0.5969171592180543</td>\n      <td>-0.03271988515836363</td>\n      <td>0.22249206804431765</td>\n      <td>2.0278810990021037</td>\n      <td>0.827870212403462</td>\n      <td>...</td>\n      <td>0.6548517055350448</td>\n      <td>-0.38468799598436426</td>\n      <td>1.1044825047930154</td>\n      <td>0.3155223956828208</td>\n      <td>-2.8847950848931903</td>\n      <td>-0.7553962498890037</td>\n      <td>-1.4720945990902772</td>\n      <td>2.653286573843067</td>\n      <td>0.19436177212666456</td>\n      <td>0.1434588478106824]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[-0.22001658113151915</td>\n      <td>-2.2507345794274003</td>\n      <td>-0.39334745766392143</td>\n      <td>-0.22047120988704638</td>\n      <td>-0.7654681601639308</td>\n      <td>-1.142924618070034</td>\n      <td>-1.86187248369162</td>\n      <td>-2.3556492318840334</td>\n      <td>0.4819600693957551</td>\n      <td>0.18859658647643737</td>\n      <td>...</td>\n      <td>-2.9357195712888546</td>\n      <td>-1.4991282068852751</td>\n      <td>1.0062288988970693</td>\n      <td>-0.8182551957518548</td>\n      <td>-0.03623077012179573</td>\n      <td>-1.7267140207545708</td>\n      <td>0.42753339462984424</td>\n      <td>-0.2442145154380059</td>\n      <td>1.433941992453667</td>\n      <td>-1.8641315484083514]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[1.597802667104453</td>\n      <td>-1.3318458039597452</td>\n      <td>-1.7876896274176677</td>\n      <td>0.1531999657748357</td>\n      <td>-0.9184955153229891</td>\n      <td>-0.5461559025055277</td>\n      <td>-1.3570081626634485</td>\n      <td>1.0627681533667157</td>\n      <td>0.9851826480709566</td>\n      <td>1.2266712267690123</td>\n      <td>...</td>\n      <td>-0.08874881949668298</td>\n      <td>-2.042117278138647</td>\n      <td>0.44127326653992904</td>\n      <td>-0.11127071569812472</td>\n      <td>0.013890977112452017</td>\n      <td>0.95533802751127</td>\n      <td>-0.8402656332947769</td>\n      <td>0.061700693517540386</td>\n      <td>1.174434637245242</td>\n      <td>-1.3317815829510649]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[-0.08318374597228116</td>\n      <td>-0.8729878666888199</td>\n      <td>0.04103715385277553</td>\n      <td>0.4616454791874244</td>\n      <td>-1.2901850509770025</td>\n      <td>-0.32690479632566644</td>\n      <td>-1.1119495148239313</td>\n      <td>-0.4324641976679138</td>\n      <td>1.0586961520473588</td>\n      <td>-1.0272654039747169</td>\n      <td>...</td>\n      <td>-1.0450595649908427</td>\n      <td>-0.21682913857705483</td>\n      <td>0.5135529541165453</td>\n      <td>0.24952462880443266</td>\n      <td>-0.4754690515821106</td>\n      <td>-0.8941292800735631</td>\n      <td>0.7727549164157642</td>\n      <td>1.0482704489062364</td>\n      <td>0.7197991172110915</td>\n      <td>0.45537440922683853]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[-2.879218311253632</td>\n      <td>-1.2799126645257008</td>\n      <td>1.4575141945832106</td>\n      <td>-1.166744513134016</td>\n      <td>-1.3042470403141233</td>\n      <td>-2.9598892548443834</td>\n      <td>-3.275919495479953</td>\n      <td>-0.8904921384608795</td>\n      <td>3.356320868826463</td>\n      <td>-2.58905896196911</td>\n      <td>...</td>\n      <td>-1.6676139719707401</td>\n      <td>-1.561016979377544</td>\n      <td>-0.6728326083361991</td>\n      <td>0.4044155336332753</td>\n      <td>-0.7633771138154553</td>\n      <td>-3.7231811983314644</td>\n      <td>1.7113150440592182</td>\n      <td>0.6782706184706131</td>\n      <td>1.3848466663654022</td>\n      <td>-0.3254715591507867]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[-0.8369180614741538</td>\n      <td>-0.9360479342720077</td>\n      <td>-1.4600495143301906</td>\n      <td>0.6728528936018906</td>\n      <td>-2.0424073705869854</td>\n      <td>0.8780426693652943</td>\n      <td>0.6503694747009278</td>\n      <td>-0.7550821150290333</td>\n      <td>0.987214469378856</td>\n      <td>-1.8657573549489026</td>\n      <td>...</td>\n      <td>-0.7416060416975647</td>\n      <td>-0.03952623912108067</td>\n      <td>0.7452824610817166</td>\n      <td>1.3450202088510912</td>\n      <td>-1.0320636113872825</td>\n      <td>-0.36690024502287766</td>\n      <td>-0.3993312144790031</td>\n      <td>1.434885437273656</td>\n      <td>0.22887428557260156</td>\n      <td>1.6715811412887076]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[0.41522979898676204</td>\n      <td>-1.159737958953214</td>\n      <td>-0.24958176524187306</td>\n      <td>-0.13623317566661258</td>\n      <td>-0.0028182256505899146</td>\n      <td>-0.113359035790069</td>\n      <td>-1.5764256339857223</td>\n      <td>-2.286969566939029</td>\n      <td>0.7884043577574544</td>\n      <td>-0.8258271395134206</td>\n      <td>...</td>\n      <td>0.9086259165978999</td>\n      <td>-0.9989015212295889</td>\n      <td>-0.6314352109646598</td>\n      <td>-2.632272249209213</td>\n      <td>-1.091078694284572</td>\n      <td>-0.06114190398377731</td>\n      <td>0.013034119396266025</td>\n      <td>0.23678484198785382</td>\n      <td>1.3449782613104728</td>\n      <td>-0.538909557924523]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[-2.9608902166864195</td>\n      <td>-1.0956738286472025</td>\n      <td>1.5058700002833443</td>\n      <td>-1.4171404701882868</td>\n      <td>-1.330844679769079</td>\n      <td>-3.2280216641241934</td>\n      <td>-2.914351798926398</td>\n      <td>-0.15371908870942233</td>\n      <td>3.7869134416421</td>\n      <td>-3.0848926771574683</td>\n      <td>...</td>\n      <td>-1.0075266551915474</td>\n      <td>-1.431580054894582</td>\n      <td>-0.9603913965546478</td>\n      <td>0.6739031904247236</td>\n      <td>-0.7635178779790973</td>\n      <td>-3.653489183589961</td>\n      <td>1.4316337850813414</td>\n      <td>0.8270008493919788</td>\n      <td>1.434033033769334</td>\n      <td>0.030364470567248808]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[-0.21947748986132684</td>\n      <td>-2.2178541207713884</td>\n      <td>-0.41563905313300975</td>\n      <td>-0.22944012568942837</td>\n      <td>-0.7795311621539934</td>\n      <td>-1.1547154513449471</td>\n      <td>-1.8051821470791596</td>\n      <td>-2.2811334928079656</td>\n      <td>0.5249316969983312</td>\n      <td>0.20879004035050058</td>\n      <td>...</td>\n      <td>-2.856059562474998</td>\n      <td>-1.5353509528367395</td>\n      <td>0.9520496397599718</td>\n      <td>-0.7985087925155984</td>\n      <td>-0.04356704773773685</td>\n      <td>-1.7113681682832265</td>\n      <td>0.4324085498406598</td>\n      <td>-0.2619146641405508</td>\n      <td>1.4221927650774926</td>\n      <td>-1.854721102828428]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[1.636401249004699</td>\n      <td>-1.3215432693000375</td>\n      <td>-1.799365303324645</td>\n      <td>0.12268648799344105</td>\n      <td>-0.9487439002267276</td>\n      <td>-0.5580854809242989</td>\n      <td>-1.336901155508226</td>\n      <td>1.116053957525558</td>\n      <td>1.0041238951464682</td>\n      <td>1.2598132746366242</td>\n      <td>...</td>\n      <td>-0.05103576905599793</td>\n      <td>-2.083416129378853</td>\n      <td>0.4702529315839726</td>\n      <td>-0.10329644329994535</td>\n      <td>0.04284644537085021</td>\n      <td>0.9636512408517387</td>\n      <td>-0.8638822929503234</td>\n      <td>0.02346379734516011</td>\n      <td>1.211031653527771</td>\n      <td>-1.348301502039101]</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 100 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expanding features df, because currently there is only one column where each row contains a list of meaning values, to make it work for PCA method defined in sklearn library, it needs to be a df where each cell is only one number\n",
    "features_X_expanded = features_X.meaning_vectors.str.split(\",\",expand=True,)\n",
    "features_X_expanded.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "100"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_X_expanded.columns)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-ddb9d4d8d691>:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  fixed_first_column = features_X_expanded[0].str.replace(\"[\",\"\")\n",
      "<ipython-input-9-ddb9d4d8d691>:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  fixed_last_column = features_X_expanded[99].str.replace(\"]\",\"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": "                     0                     1                      2   \\\n0   -1.0013970414243027   0.10410662986918126    -0.7069594929319728   \n1  -0.22001658113151915   -2.2507345794274003   -0.39334745766392143   \n2     1.597802667104453   -1.3318458039597452    -1.7876896274176677   \n3  -0.08318374597228116   -0.8729878666888199    0.04103715385277553   \n4    -2.879218311253632   -1.2799126645257008     1.4575141945832106   \n\n                      3                     4                      5   \\\n0   -0.36709259026598773   -2.1300366871439413     0.5969171592180543   \n1   -0.22047120988704638   -0.7654681601639308     -1.142924618070034   \n2     0.1531999657748357   -0.9184955153229891    -0.5461559025055277   \n3     0.4616454791874244   -1.2901850509770025   -0.32690479632566644   \n4     -1.166744513134016   -1.3042470403141233    -2.9598892548443834   \n\n                      6                     7                    8   \\\n0   -0.03271988515836363   0.22249206804431765   2.0278810990021037   \n1      -1.86187248369162   -2.3556492318840334   0.4819600693957551   \n2    -1.3570081626634485    1.0627681533667157   0.9851826480709566   \n3    -1.1119495148239313   -0.4324641976679138   1.0586961520473588   \n4     -3.275919495479953   -0.8904921384608795    3.356320868826463   \n\n                     9   ...                     90                     91  \\\n0     0.827870212403462  ...     0.6548517055350448   -0.38468799598436426   \n1   0.18859658647643737  ...    -2.9357195712888546    -1.4991282068852751   \n2    1.2266712267690123  ...   -0.08874881949668298     -2.042117278138647   \n3   -1.0272654039747169  ...    -1.0450595649908427   -0.21682913857705483   \n4     -2.58905896196911  ...    -1.6676139719707401     -1.561016979377544   \n\n                     92                     93                     94  \\\n0    1.1044825047930154     0.3155223956828208    -2.8847950848931903   \n1    1.0062288988970693    -0.8182551957518548   -0.03623077012179573   \n2   0.44127326653992904   -0.11127071569812472   0.013890977112452017   \n3    0.5135529541165453    0.24952462880443266    -0.4754690515821106   \n4   -0.6728326083361991     0.4044155336332753    -0.7633771138154553   \n\n                     95                    96                     97  \\\n0   -0.7553962498890037   -1.4720945990902772      2.653286573843067   \n1   -1.7267140207545708   0.42753339462984424    -0.2442145154380059   \n2      0.95533802751127   -0.8402656332947769   0.061700693517540386   \n3   -0.8941292800735631    0.7727549164157642     1.0482704489062364   \n4   -3.7231811983314644    1.7113150440592182     0.6782706184706131   \n\n                     98                    99  \n0   0.19436177212666456    0.1434588478106824  \n1     1.433941992453667   -1.8641315484083514  \n2     1.174434637245242   -1.3317815829510649  \n3    0.7197991172110915   0.45537440922683853  \n4    1.3848466663654022   -0.3254715591507867  \n\n[5 rows x 100 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n      <th>94</th>\n      <th>95</th>\n      <th>96</th>\n      <th>97</th>\n      <th>98</th>\n      <th>99</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.0013970414243027</td>\n      <td>0.10410662986918126</td>\n      <td>-0.7069594929319728</td>\n      <td>-0.36709259026598773</td>\n      <td>-2.1300366871439413</td>\n      <td>0.5969171592180543</td>\n      <td>-0.03271988515836363</td>\n      <td>0.22249206804431765</td>\n      <td>2.0278810990021037</td>\n      <td>0.827870212403462</td>\n      <td>...</td>\n      <td>0.6548517055350448</td>\n      <td>-0.38468799598436426</td>\n      <td>1.1044825047930154</td>\n      <td>0.3155223956828208</td>\n      <td>-2.8847950848931903</td>\n      <td>-0.7553962498890037</td>\n      <td>-1.4720945990902772</td>\n      <td>2.653286573843067</td>\n      <td>0.19436177212666456</td>\n      <td>0.1434588478106824</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.22001658113151915</td>\n      <td>-2.2507345794274003</td>\n      <td>-0.39334745766392143</td>\n      <td>-0.22047120988704638</td>\n      <td>-0.7654681601639308</td>\n      <td>-1.142924618070034</td>\n      <td>-1.86187248369162</td>\n      <td>-2.3556492318840334</td>\n      <td>0.4819600693957551</td>\n      <td>0.18859658647643737</td>\n      <td>...</td>\n      <td>-2.9357195712888546</td>\n      <td>-1.4991282068852751</td>\n      <td>1.0062288988970693</td>\n      <td>-0.8182551957518548</td>\n      <td>-0.03623077012179573</td>\n      <td>-1.7267140207545708</td>\n      <td>0.42753339462984424</td>\n      <td>-0.2442145154380059</td>\n      <td>1.433941992453667</td>\n      <td>-1.8641315484083514</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.597802667104453</td>\n      <td>-1.3318458039597452</td>\n      <td>-1.7876896274176677</td>\n      <td>0.1531999657748357</td>\n      <td>-0.9184955153229891</td>\n      <td>-0.5461559025055277</td>\n      <td>-1.3570081626634485</td>\n      <td>1.0627681533667157</td>\n      <td>0.9851826480709566</td>\n      <td>1.2266712267690123</td>\n      <td>...</td>\n      <td>-0.08874881949668298</td>\n      <td>-2.042117278138647</td>\n      <td>0.44127326653992904</td>\n      <td>-0.11127071569812472</td>\n      <td>0.013890977112452017</td>\n      <td>0.95533802751127</td>\n      <td>-0.8402656332947769</td>\n      <td>0.061700693517540386</td>\n      <td>1.174434637245242</td>\n      <td>-1.3317815829510649</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.08318374597228116</td>\n      <td>-0.8729878666888199</td>\n      <td>0.04103715385277553</td>\n      <td>0.4616454791874244</td>\n      <td>-1.2901850509770025</td>\n      <td>-0.32690479632566644</td>\n      <td>-1.1119495148239313</td>\n      <td>-0.4324641976679138</td>\n      <td>1.0586961520473588</td>\n      <td>-1.0272654039747169</td>\n      <td>...</td>\n      <td>-1.0450595649908427</td>\n      <td>-0.21682913857705483</td>\n      <td>0.5135529541165453</td>\n      <td>0.24952462880443266</td>\n      <td>-0.4754690515821106</td>\n      <td>-0.8941292800735631</td>\n      <td>0.7727549164157642</td>\n      <td>1.0482704489062364</td>\n      <td>0.7197991172110915</td>\n      <td>0.45537440922683853</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-2.879218311253632</td>\n      <td>-1.2799126645257008</td>\n      <td>1.4575141945832106</td>\n      <td>-1.166744513134016</td>\n      <td>-1.3042470403141233</td>\n      <td>-2.9598892548443834</td>\n      <td>-3.275919495479953</td>\n      <td>-0.8904921384608795</td>\n      <td>3.356320868826463</td>\n      <td>-2.58905896196911</td>\n      <td>...</td>\n      <td>-1.6676139719707401</td>\n      <td>-1.561016979377544</td>\n      <td>-0.6728326083361991</td>\n      <td>0.4044155336332753</td>\n      <td>-0.7633771138154553</td>\n      <td>-3.7231811983314644</td>\n      <td>1.7113150440592182</td>\n      <td>0.6782706184706131</td>\n      <td>1.3848466663654022</td>\n      <td>-0.3254715591507867</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 100 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since we have expanded a string of list, we also have to remove \"[\" and \"]\" from first and last column\n",
    "fixed_first_column = features_X_expanded[0].str.replace(\"[\",\"\")\n",
    "fixed_last_column = features_X_expanded[99].str.replace(\"]\",\"\")\n",
    "\n",
    "features_X_expanded[0] = fixed_first_column\n",
    "features_X_expanded[99] = fixed_last_column\n",
    "\n",
    "features_X_expanded.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([2.98996470e-01, 2.11891189e-01, 1.12035474e-01, 7.02827623e-02,\n       4.42911795e-02, 3.53171876e-02, 2.66142582e-02, 2.60331257e-02,\n       1.82677849e-02, 1.51562176e-02, 1.37380363e-02, 1.08030752e-02,\n       9.58648404e-03, 9.04959142e-03, 8.06761604e-03, 7.52823087e-03,\n       7.04622432e-03, 6.38222820e-03, 5.27454212e-03, 4.53812788e-03,\n       4.16271650e-03, 3.87301135e-03, 3.40864161e-03, 3.13457123e-03,\n       2.77584737e-03, 2.48966454e-03, 2.32236824e-03, 2.27391186e-03,\n       2.09303313e-03, 1.90118136e-03, 1.80413060e-03, 1.72815189e-03,\n       1.58408752e-03, 1.54583189e-03, 1.31452776e-03, 1.24106202e-03,\n       1.22713516e-03, 1.15302936e-03, 1.11745119e-03, 9.68696407e-04,\n       9.29676107e-04, 8.91753351e-04, 8.48408037e-04, 8.29184205e-04,\n       7.37714830e-04, 6.65066222e-04, 6.41614633e-04, 6.16185782e-04,\n       5.95594978e-04, 5.52744107e-04, 5.10939463e-04, 5.00563107e-04,\n       4.90475347e-04, 4.47907681e-04, 4.29382134e-04, 3.93093167e-04,\n       3.82512569e-04, 3.76409835e-04, 3.40309327e-04, 3.21296773e-04,\n       2.98080542e-04, 2.87807780e-04, 2.78372533e-04, 2.68580395e-04,\n       2.62191309e-04, 2.40871284e-04, 2.24468245e-04, 2.11597638e-04,\n       2.03627420e-04, 2.03014982e-04, 1.92189673e-04, 1.78390851e-04,\n       1.70391871e-04, 1.67556845e-04, 1.52864671e-04, 1.49565421e-04,\n       1.45460494e-04, 1.41568560e-04, 1.38580662e-04, 1.24162969e-04,\n       1.19506833e-04, 1.10630153e-04, 1.06079376e-04, 1.02073602e-04,\n       9.50274496e-05, 9.15772808e-05, 8.63550747e-05, 8.54389976e-05,\n       7.82727173e-05, 7.39385420e-05, 6.69044701e-05, 6.23570164e-05,\n       5.99471421e-05, 5.77901229e-05, 5.50758293e-05, 5.24627113e-05,\n       5.00913933e-05, 4.65170411e-05, 3.95524373e-05, 1.37005908e-06])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform PCA on all data\n",
    "# first create train and test\n",
    "features_X_expanded[\"Labels\"] = labels_Y # appending labels to not lose their assigned labels when performing data split\n",
    "train, test = train_test_split(features_X_expanded, test_size=0.2)\n",
    "\n",
    "# saving labels\n",
    "train_labels = train.pop(\"Labels\")\n",
    "features_X_expanded = train\n",
    "\n",
    "test_labels = test.pop(\"Labels\")\n",
    "\n",
    "# Scaling features such that they all have a mean of 0 and a variance of 1\n",
    "scaler = StandardScaler()\n",
    "scaled_train = scaler.fit_transform(features_X_expanded)\n",
    "\n",
    "pca = PCA() # can be replaced with \"PCA(n_components=2)\" but need to check variance ratio first\n",
    "pca_train = pca.fit_transform(scaled_train)\n",
    "\n",
    "pca.explained_variance_ratio_ # observing how much each PCA is responsible for the variance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# pca_train_allPCs_df = pd.DataFrame(pca_train, columns = [*range(0, pca_train.shape[1])])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# extracting all PCs data to cvs file\n",
    "# pca_train_allPCs_df.to_csv(\"C:/Users/dnaen/APG_data/pca_train_allPCs.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2) # to be able to do Euclidean distance calculation set to 2\n",
    "pca_train_2PCs = pca.fit_transform(scaled_train)\n",
    "pca_train_2PCs_df = pd.DataFrame(pca_train_2PCs, columns = ['PC1','PC2'])\n",
    "pca_train_2PCs_df[\"Labels\"] = train_labels # can just append it since row order is not affected"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# setting up test\n",
    "scaled_test = scaler.transform(test)\n",
    "pca_test_2PCs = pca.transform(scaled_test)\n",
    "\n",
    "pca_test_2PCs_df = pd.DataFrame(pca_test_2PCs, columns = ['PC1','PC2'])\n",
    "pca_test_2PCs_df[\"Labels\"] = test_labels # can just append it since row order is not affected"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# to extract file to csv\n",
    "# pca_data_2PCs_df.to_csv(\"C:/Users/dnaen/APG_data/pca_data_2PCs.csv\", index=False)\n",
    "\n",
    "# to extract from csv\n",
    "# pca_data_2PCs_df = pd.read_csv(\".../pca_data_2PCs.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "          0         1\n0 -0.006485 -0.000891\n1 -0.079668  0.051100\n2 -0.044950  0.078890\n3  0.287227 -0.223247\n4  0.207624 -0.131277",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.006485</td>\n      <td>-0.000891</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.079668</td>\n      <td>0.051100</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.044950</td>\n      <td>0.078890</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.287227</td>\n      <td>-0.223247</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.207624</td>\n      <td>-0.131277</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to use at visit prob. calculation later\n",
    "pca_train_2PCs_df_sorted = pca_train_2PCs_df.sort_values(by=[\"Labels\"])\n",
    "avg_pca_train_2PCs_df = get_avg_pca(pca_train_2PCs_df_sorted)\n",
    "avg_pca_train_2PCs_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# experiment 1 - done for 2 PCs going through all PCA\n",
    "accurate_estimation_prob = 0\n",
    "false_estimation_prob = 0\n",
    "\n",
    "total_accurate_prob = 0\n",
    "total_false_prob = 0\n",
    "\n",
    "# row size (number of data points)\n",
    "row_size = len(pca_test_2PCs_df.axes[0])\n",
    "experiment_size = 2\n",
    "random_list = [] # for experiment\n",
    "for y in range(0, experiment_size):\n",
    "    random_list.append(random.randint(0, row_size))\n",
    "\n",
    "# only using \"pca_test_2comp_df_sorted\" such that labels match\n",
    "for x in random_list:\n",
    "    label = pca_test_2PCs_df.at[pca_test_2PCs_df.index[x], \"Labels\"]\n",
    "    if label >= 0:\n",
    "        current_visit = pca_test_2PCs_df.iloc[x]\n",
    "        current_visit = current_visit.tolist()\n",
    "        current_visit = current_visit[:-1]\n",
    "\n",
    "        estimated_prob, estimated_label = calculate_prob_of_visit_without_sorting(current_visit, pca_train_2PCs_df_sorted)\n",
    "\n",
    "        if estimated_label == label:\n",
    "            total_accurate_prob += estimated_prob\n",
    "        else:\n",
    "            total_false_prob += estimated_prob\n",
    "\n",
    "accurate_estimation_prob = total_accurate_prob / experiment_size\n",
    "false_estimation_prob = total_false_prob / experiment_size\n",
    "\n",
    "print(\"Experiment size:\")\n",
    "print(experiment_size)\n",
    "print(\"Accurate prediction with prob.\")\n",
    "print(accurate_estimation_prob)\n",
    "print(\"False prediction with prob.\")\n",
    "print(false_estimation_prob)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Can save results here\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment size:\n",
      "100\n",
      "Accurate prediction with prob.\n",
      "411.42\n",
      "False prediction with prob.\n",
      "157.76\n"
     ]
    }
   ],
   "source": [
    "# experiment 2 - done for 2 PCs with averaged PCA\n",
    "accurate_estimation_prob = 0\n",
    "false_estimation_prob = 0\n",
    "\n",
    "total_accurate_prob = 0\n",
    "total_false_prob = 0\n",
    "\n",
    "# row size (number of data points)\n",
    "row_size = len(pca_test_2PCs_df.axes[0])\n",
    "experiment_size = row_size\n",
    "random_list = [] # for experiment\n",
    "\n",
    "for x in range(0, experiment_size):\n",
    "    label = pca_test_2PCs_df.at[pca_test_2PCs_df.index[x], \"Labels\"]\n",
    "    if label >= 0:\n",
    "        current_visit = pca_test_2PCs_df.iloc[x]\n",
    "        current_visit = current_visit.tolist()\n",
    "        current_visit = current_visit[:-1]\n",
    "        estimated_prob, estimated_label = calculate_prob_of_visit_with_sorted_avg_pca(current_visit, avg_pca_train_2PCs_df) # visit extracted from test data, pca extracted from train data\n",
    "\n",
    "        if estimated_label == label:\n",
    "            total_accurate_prob += estimated_prob\n",
    "        else:\n",
    "            total_false_prob += estimated_prob\n",
    "\n",
    "accurate_estimation_prob = total_accurate_prob / experiment_size\n",
    "false_estimation_prob = total_false_prob / experiment_size\n",
    "\n",
    "print(\"Experiment size:\")\n",
    "print(experiment_size)\n",
    "print(\"Accurate prediction with prob.\")\n",
    "print(accurate_estimation_prob)\n",
    "print(\"False prediction with prob.\")\n",
    "print(false_estimation_prob)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- with split -\n",
    "Experiment size:\n",
    "1438474\n",
    "Accurate prediction with prob.\n",
    "0.1430056135838301\n",
    "False prediction with prob.\n",
    "0.05483585046664002\n",
    "- without split -\n",
    "Experiment size:\n",
    "1438474\n",
    "Accurate prediction with prob.\n",
    "0.6983720247985018\n",
    "False prediction with prob.\n",
    "0.2959629440643348\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
